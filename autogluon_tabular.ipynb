{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9276e8c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Unnamed: 0",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "year",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "month",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "day",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "hour",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "min",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "sec",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "lat",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "lon",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "depth",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "class",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "year_as",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "month_as",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "day_as",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "hour_as",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "min_as",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "sec_as",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "lat_as",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "lon_as",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "depth_as",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "class_as",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "23090397-a80a-46c7-b3b2-ee14e6a5e3c1",
       "rows": [
        [
         "0",
         "0",
         "1980",
         "2",
         "15",
         "9",
         "9",
         "350",
         "40.54",
         "78.31",
         "-1",
         "12.0",
         "1980",
         "2",
         "15",
         "9",
         "45",
         "540",
         "40.45",
         "78.24",
         "-1",
         "7.7"
        ],
        [
         "1",
         "1",
         "1980",
         "3",
         "16",
         "1",
         "44",
         "30",
         "41.42",
         "75.4",
         "-1",
         "10.4",
         "1980",
         "3",
         "25",
         "10",
         "58",
         "236",
         "41.4",
         "75.42",
         "-1",
         "8.7"
        ],
        [
         "2",
         "2",
         "1980",
         "7",
         "5",
         "20",
         "25",
         "220",
         "41.46",
         "77.3",
         "20",
         "13.6",
         "1980",
         "7",
         "5",
         "21",
         "41",
         "335",
         "41.56",
         "77.25",
         "5",
         "7.3"
        ],
        [
         "3",
         "3",
         "1980",
         "8",
         "31",
         "23",
         "38",
         "372",
         "40.52",
         "77.46",
         "-1",
         "11.9",
         "1980",
         "9",
         "4",
         "22",
         "56",
         "92",
         "40.51",
         "77.37",
         "-1",
         "7.3"
        ],
        [
         "4",
         "4",
         "1980",
         "9",
         "4",
         "6",
         "47",
         "166",
         "44.16",
         "79.08",
         "10",
         "12.4",
         "1980",
         "9",
         "14",
         "9",
         "16",
         "160",
         "44.18",
         "79.3",
         "-1",
         "7.2"
        ],
        [
         "5",
         "5",
         "1980",
         "9",
         "22",
         "15",
         "33",
         "552",
         "44.37",
         "79.4",
         "-1",
         "10.6",
         "1980",
         "9",
         "24",
         "10",
         "19",
         "232",
         "44.39",
         "79.3",
         "-1",
         "9.5"
        ],
        [
         "6",
         "6",
         "1980",
         "9",
         "30",
         "0",
         "18",
         "388",
         "43.29",
         "75.13",
         "-1",
         "11.2",
         "1980",
         "9",
         "30",
         "9",
         "51",
         "60",
         "43.31",
         "75.08",
         "-1",
         "7.3"
        ],
        [
         "7",
         "7",
         "1980",
         "10",
         "5",
         "14",
         "34",
         "292",
         "42.09",
         "76.39",
         "5",
         "10.1",
         "1980",
         "10",
         "19",
         "10",
         "7",
         "213",
         "42.17",
         "76.2",
         "-1",
         "7.3"
        ],
        [
         "8",
         "8",
         "1980",
         "10",
         "7",
         "22",
         "49",
         "320",
         "40.07",
         "77.28",
         "-1",
         "11.9",
         "1980",
         "10",
         "9",
         "4",
         "28",
         "0",
         "40.34",
         "77.28",
         "-1",
         "8.0"
        ],
        [
         "9",
         "9",
         "1980",
         "10",
         "19",
         "10",
         "52",
         "480",
         "44.21",
         "79.24",
         "-1",
         "11.8",
         "1980",
         "10",
         "19",
         "14",
         "33",
         "332",
         "44.18",
         "79.14",
         "-1",
         "8.9"
        ],
        [
         "10",
         "10",
         "1980",
         "11",
         "5",
         "15",
         "22",
         "532",
         "42.16",
         "76.02",
         "15",
         "10.1",
         "1980",
         "11",
         "17",
         "0",
         "11",
         "108",
         "42.22",
         "76.04",
         "25",
         "9.2"
        ],
        [
         "11",
         "11",
         "1980",
         "11",
         "14",
         "1",
         "48",
         "58",
         "41.39",
         "74.04",
         "22",
         "10.6",
         "1980",
         "11",
         "26",
         "14",
         "34",
         "328",
         "41.32",
         "74.08",
         "-1",
         "7.5"
        ],
        [
         "12",
         "12",
         "1980",
         "12",
         "2",
         "18",
         "18",
         "592",
         "44.22",
         "80.5",
         "-1",
         "10.1",
         "1980",
         "12",
         "2",
         "19",
         "17",
         "300",
         "44.24",
         "80.51",
         "-1",
         "7.9"
        ],
        [
         "13",
         "13",
         "1981",
         "1",
         "13",
         "2",
         "30",
         "486",
         "40.03",
         "77.28",
         "-1",
         "10.2",
         "1981",
         "1",
         "15",
         "22",
         "43",
         "300",
         "40.14",
         "77.32",
         "-1",
         "8.6"
        ],
        [
         "14",
         "14",
         "1981",
         "2",
         "20",
         "10",
         "12",
         "380",
         "40.26",
         "76.53",
         "-1",
         "11.8",
         "1981",
         "3",
         "5",
         "4",
         "16",
         "590",
         "40.22",
         "76.55",
         "-1",
         "8.0"
        ],
        [
         "15",
         "15",
         "1981",
         "2",
         "22",
         "16",
         "9",
         "228",
         "42.18",
         "76.25",
         "15",
         "10.3",
         "1981",
         "3",
         "3",
         "10",
         "5",
         "420",
         "42.08",
         "76.34",
         "-1",
         "8.4"
        ],
        [
         "16",
         "16",
         "1981",
         "4",
         "9",
         "0",
         "35",
         "76",
         "41.49",
         "79.55",
         "-1",
         "10.5",
         "1981",
         "4",
         "10",
         "5",
         "24",
         "156",
         "41.58",
         "79.22",
         "-1",
         "9.1"
        ],
        [
         "17",
         "17",
         "1981",
         "6",
         "1",
         "6",
         "1",
         "440",
         "41.0",
         "78.05",
         "-1",
         "11.7",
         "1981",
         "6",
         "1",
         "6",
         "49",
         "288",
         "41.0",
         "78.08",
         "-1",
         "7.7"
        ],
        [
         "18",
         "18",
         "1981",
         "6",
         "13",
         "6",
         "14",
         "250",
         "41.2",
         "78.4",
         "-1",
         "10.8",
         "1981",
         "6",
         "22",
         "11",
         "28",
         "156",
         "41.06",
         "78.46",
         "-1",
         "8.4"
        ],
        [
         "19",
         "19",
         "1981",
         "6",
         "25",
         "10",
         "21",
         "58",
         "40.23",
         "77.28",
         "-1",
         "11.0",
         "1981",
         "7",
         "2",
         "23",
         "22",
         "552",
         "40.26",
         "77.01",
         "-1",
         "9.2"
        ],
        [
         "20",
         "20",
         "1981",
         "6",
         "30",
         "19",
         "32",
         "330",
         "43.06",
         "77.24",
         "15",
         "11.0",
         "1981",
         "7",
         "10",
         "10",
         "1",
         "395",
         "43.01",
         "77.19",
         "15",
         "5.4"
        ],
        [
         "21",
         "21",
         "1981",
         "7",
         "29",
         "2",
         "14",
         "464",
         "41.16",
         "78.31",
         "-1",
         "10.2",
         "1981",
         "7",
         "29",
         "3",
         "39",
         "466",
         "41.16",
         "78.4",
         "-1",
         "7.9"
        ],
        [
         "22",
         "22",
         "1981",
         "8",
         "6",
         "18",
         "30",
         "472",
         "40.17",
         "77.11",
         "-1",
         "11.4",
         "1981",
         "8",
         "6",
         "21",
         "7",
         "444",
         "40.28",
         "77.07",
         "-1",
         "7.9"
        ],
        [
         "23",
         "23",
         "1981",
         "8",
         "30",
         "4",
         "4",
         "488",
         "42.48",
         "78.29",
         "10",
         "11.8",
         "1981",
         "8",
         "30",
         "4",
         "39",
         "296",
         "42.5",
         "78.27",
         "15",
         "8.2"
        ],
        [
         "24",
         "24",
         "1981",
         "11",
         "4",
         "3",
         "54",
         "332",
         "40.57",
         "77.33",
         "-1",
         "10.3",
         "1981",
         "11",
         "13",
         "6",
         "39",
         "448",
         "40.41",
         "77.34",
         "-1",
         "9.6"
        ],
        [
         "25",
         "25",
         "1981",
         "11",
         "10",
         "11",
         "28",
         "480",
         "43.55",
         "75.48",
         "-1",
         "10.8",
         "1981",
         "11",
         "10",
         "13",
         "31",
         "364",
         "43.55",
         "75.5",
         "10",
         "7.1"
        ],
        [
         "26",
         "26",
         "1981",
         "12",
         "13",
         "17",
         "46",
         "56",
         "41.54",
         "78.28",
         "-1",
         "10.5",
         "1981",
         "12",
         "14",
         "0",
         "21",
         "92",
         "41.51",
         "78.24",
         "-1",
         "7.2"
        ],
        [
         "27",
         "27",
         "1981",
         "12",
         "14",
         "13",
         "57",
         "44",
         "43.42",
         "78.03",
         "5",
         "10.1",
         "1981",
         "12",
         "18",
         "1",
         "32",
         "100",
         "43.27",
         "78.23",
         "-1",
         "6.4"
        ],
        [
         "28",
         "28",
         "1981",
         "12",
         "18",
         "5",
         "46",
         "260",
         "40.08",
         "78.1",
         "-1",
         "11.5",
         "1981",
         "12",
         "22",
         "8",
         "54",
         "266",
         "40.26",
         "78.22",
         "-1",
         "8.1"
        ],
        [
         "29",
         "29",
         "1981",
         "12",
         "24",
         "14",
         "7",
         "360",
         "40.1",
         "77.08",
         "-1",
         "12.0",
         "1981",
         "12",
         "26",
         "10",
         "33",
         "116",
         "40.3",
         "77.21",
         "-1",
         "8.8"
        ],
        [
         "30",
         "30",
         "1982",
         "2",
         "1",
         "1",
         "29",
         "72",
         "41.51",
         "79.21",
         "-1",
         "11.2",
         "1982",
         "2",
         "5",
         "22",
         "54",
         "268",
         "41.46",
         "79.28",
         "-1",
         "7.8"
        ],
        [
         "31",
         "31",
         "1982",
         "2",
         "23",
         "12",
         "23",
         "556",
         "40.36",
         "77.25",
         "-1",
         "12.0",
         "1982",
         "2",
         "23",
         "13",
         "28",
         "230",
         "40.39",
         "77.29",
         "-1",
         "7.9"
        ],
        [
         "32",
         "32",
         "1982",
         "4",
         "3",
         "10",
         "26",
         "40",
         "40.16",
         "76.22",
         "-1",
         "11.6",
         "1982",
         "4",
         "10",
         "0",
         "23",
         "452",
         "40.27",
         "76.51",
         "-1",
         "7.1"
        ],
        [
         "33",
         "33",
         "1982",
         "5",
         "18",
         "0",
         "42",
         "95",
         "40.23",
         "77.22",
         "-1",
         "10.3",
         "1982",
         "5",
         "20",
         "10",
         "1",
         "60",
         "40.2",
         "77.25",
         "-1",
         "9.3"
        ],
        [
         "34",
         "34",
         "1982",
         "5",
         "19",
         "16",
         "33",
         "550",
         "40.58",
         "78.22",
         "-1",
         "12.2",
         "1982",
         "5",
         "19",
         "19",
         "13",
         "492",
         "40.45",
         "78.12",
         "-1",
         "7.2"
        ],
        [
         "35",
         "35",
         "1982",
         "6",
         "2",
         "10",
         "5",
         "588",
         "42.42",
         "76.12",
         "20",
         "11.8",
         "1982",
         "6",
         "3",
         "8",
         "31",
         "390",
         "42.16",
         "76.07",
         "-1",
         "6.5"
        ],
        [
         "36",
         "36",
         "1982",
         "8",
         "12",
         "1",
         "54",
         "540",
         "40.16",
         "77.42",
         "-1",
         "10.1",
         "1982",
         "8",
         "21",
         "3",
         "5",
         "202",
         "40.15",
         "77.14",
         "-1",
         "8.7"
        ],
        [
         "37",
         "37",
         "1982",
         "8",
         "27",
         "23",
         "40",
         "20",
         "40.16",
         "77.2",
         "-1",
         "11.1",
         "1982",
         "8",
         "29",
         "19",
         "48",
         "72",
         "40.24",
         "77.06",
         "-1",
         "7.2"
        ],
        [
         "38",
         "38",
         "1982",
         "11",
         "10",
         "21",
         "30",
         "200",
         "42.11",
         "76.28",
         "-1",
         "11.1",
         "1982",
         "11",
         "11",
         "13",
         "42",
         "380",
         "42.13",
         "76.16",
         "-1",
         "8.1"
        ],
        [
         "39",
         "39",
         "1982",
         "12",
         "31",
         "2",
         "26",
         "10",
         "40.43",
         "78.16",
         "-1",
         "10.1",
         "1982",
         "12",
         "31",
         "2",
         "44",
         "324",
         "40.55",
         "78.23",
         "-1",
         "8.0"
        ],
        [
         "40",
         "40",
         "1982",
         "12",
         "31",
         "19",
         "46",
         "464",
         "42.52",
         "77.22",
         "18",
         "13.7",
         "1982",
         "12",
         "31",
         "20",
         "47",
         "370",
         "42.47",
         "77.11",
         "-1",
         "6.2"
        ],
        [
         "41",
         "41",
         "1983",
         "2",
         "13",
         "1",
         "40",
         "92",
         "40.08",
         "75.09",
         "-1",
         "14.6",
         "1983",
         "2",
         "13",
         "1",
         "52",
         "480",
         "40.06",
         "75.04",
         "-1",
         "13.6"
        ],
        [
         "42",
         "42",
         "1983",
         "2",
         "13",
         "1",
         "52",
         "480",
         "40.06",
         "75.04",
         "-1",
         "13.6",
         "1983",
         "2",
         "13",
         "2",
         "2",
         "56",
         "40.06",
         "75.02",
         "-1",
         "11.0"
        ],
        [
         "43",
         "43",
         "1983",
         "2",
         "13",
         "2",
         "2",
         "56",
         "40.06",
         "75.02",
         "-1",
         "11.0",
         "1983",
         "2",
         "13",
         "2",
         "6",
         "0",
         "40.06",
         "75.02",
         "-1",
         "10.6"
        ],
        [
         "44",
         "44",
         "1983",
         "2",
         "13",
         "2",
         "12",
         "150",
         "40.0",
         "75.18",
         "-1",
         "11.9",
         "1983",
         "2",
         "13",
         "2",
         "17",
         "0",
         "40.0",
         "75.18",
         "-1",
         "10.9"
        ],
        [
         "45",
         "45",
         "1983",
         "2",
         "13",
         "2",
         "22",
         "80",
         "40.0",
         "75.24",
         "-1",
         "11.1",
         "1983",
         "2",
         "13",
         "2",
         "31",
         "0",
         "40.06",
         "75.18",
         "-1",
         "9.9"
        ],
        [
         "46",
         "46",
         "1983",
         "2",
         "13",
         "2",
         "38",
         "590",
         "40.0",
         "75.14",
         "-1",
         "12.5",
         "1983",
         "2",
         "13",
         "2",
         "44",
         "373",
         "40.0",
         "75.12",
         "-1",
         "9.1"
        ],
        [
         "47",
         "47",
         "1983",
         "2",
         "13",
         "3",
         "54",
         "326",
         "40.06",
         "75.13",
         "-1",
         "11.0",
         "1983",
         "2",
         "13",
         "4",
         "1",
         "75",
         "40.13",
         "75.18",
         "-1",
         "9.1"
        ],
        [
         "48",
         "48",
         "1983",
         "2",
         "13",
         "4",
         "5",
         "485",
         "40.09",
         "75.08",
         "-1",
         "10.6",
         "1983",
         "2",
         "13",
         "4",
         "14",
         "277",
         "40.0",
         "75.12",
         "-1",
         "8.0"
        ],
        [
         "49",
         "49",
         "1983",
         "2",
         "13",
         "4",
         "18",
         "460",
         "40.05",
         "75.17",
         "-1",
         "11.6",
         "1983",
         "2",
         "13",
         "4",
         "23",
         "517",
         "40.04",
         "75.15",
         "-1",
         "11.0"
        ]
       ],
       "shape": {
        "columns": 21,
        "rows": 1250
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>min</th>\n",
       "      <th>sec</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>depth</th>\n",
       "      <th>...</th>\n",
       "      <th>year_as</th>\n",
       "      <th>month_as</th>\n",
       "      <th>day_as</th>\n",
       "      <th>hour_as</th>\n",
       "      <th>min_as</th>\n",
       "      <th>sec_as</th>\n",
       "      <th>lat_as</th>\n",
       "      <th>lon_as</th>\n",
       "      <th>depth_as</th>\n",
       "      <th>class_as</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1980</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>350</td>\n",
       "      <td>40.54</td>\n",
       "      <td>78.31</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>1980</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>45</td>\n",
       "      <td>540</td>\n",
       "      <td>40.45</td>\n",
       "      <td>78.24</td>\n",
       "      <td>-1</td>\n",
       "      <td>7.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1980</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>30</td>\n",
       "      <td>41.42</td>\n",
       "      <td>75.40</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>1980</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>10</td>\n",
       "      <td>58</td>\n",
       "      <td>236</td>\n",
       "      <td>41.40</td>\n",
       "      <td>75.42</td>\n",
       "      <td>-1</td>\n",
       "      <td>8.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1980</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>25</td>\n",
       "      <td>220</td>\n",
       "      <td>41.46</td>\n",
       "      <td>77.30</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>1980</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>21</td>\n",
       "      <td>41</td>\n",
       "      <td>335</td>\n",
       "      <td>41.56</td>\n",
       "      <td>77.25</td>\n",
       "      <td>5</td>\n",
       "      <td>7.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1980</td>\n",
       "      <td>8</td>\n",
       "      <td>31</td>\n",
       "      <td>23</td>\n",
       "      <td>38</td>\n",
       "      <td>372</td>\n",
       "      <td>40.52</td>\n",
       "      <td>77.46</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>1980</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>22</td>\n",
       "      <td>56</td>\n",
       "      <td>92</td>\n",
       "      <td>40.51</td>\n",
       "      <td>77.37</td>\n",
       "      <td>-1</td>\n",
       "      <td>7.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1980</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>47</td>\n",
       "      <td>166</td>\n",
       "      <td>44.16</td>\n",
       "      <td>79.08</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>1980</td>\n",
       "      <td>9</td>\n",
       "      <td>14</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>160</td>\n",
       "      <td>44.18</td>\n",
       "      <td>79.30</td>\n",
       "      <td>-1</td>\n",
       "      <td>7.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1245</th>\n",
       "      <td>1245</td>\n",
       "      <td>2013</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>471</td>\n",
       "      <td>44.12</td>\n",
       "      <td>81.18</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>2013</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>159</td>\n",
       "      <td>44.14</td>\n",
       "      <td>81.42</td>\n",
       "      <td>5</td>\n",
       "      <td>6.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1246</th>\n",
       "      <td>1246</td>\n",
       "      <td>2013</td>\n",
       "      <td>12</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>283</td>\n",
       "      <td>41.00</td>\n",
       "      <td>78.45</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>2013</td>\n",
       "      <td>12</td>\n",
       "      <td>24</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>388</td>\n",
       "      <td>41.04</td>\n",
       "      <td>78.44</td>\n",
       "      <td>10</td>\n",
       "      <td>7.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1247</th>\n",
       "      <td>1247</td>\n",
       "      <td>2013</td>\n",
       "      <td>12</td>\n",
       "      <td>21</td>\n",
       "      <td>14</td>\n",
       "      <td>21</td>\n",
       "      <td>464</td>\n",
       "      <td>37.12</td>\n",
       "      <td>71.31</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2013</td>\n",
       "      <td>12</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>74</td>\n",
       "      <td>37.23</td>\n",
       "      <td>71.17</td>\n",
       "      <td>5</td>\n",
       "      <td>9.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1248</th>\n",
       "      <td>1248</td>\n",
       "      <td>2013</td>\n",
       "      <td>12</td>\n",
       "      <td>22</td>\n",
       "      <td>7</td>\n",
       "      <td>45</td>\n",
       "      <td>314</td>\n",
       "      <td>38.22</td>\n",
       "      <td>72.07</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>2013</td>\n",
       "      <td>12</td>\n",
       "      <td>26</td>\n",
       "      <td>8</td>\n",
       "      <td>26</td>\n",
       "      <td>227</td>\n",
       "      <td>38.47</td>\n",
       "      <td>72.14</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1249</th>\n",
       "      <td>1249</td>\n",
       "      <td>2013</td>\n",
       "      <td>12</td>\n",
       "      <td>24</td>\n",
       "      <td>12</td>\n",
       "      <td>40</td>\n",
       "      <td>316</td>\n",
       "      <td>39.10</td>\n",
       "      <td>73.27</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>2013</td>\n",
       "      <td>12</td>\n",
       "      <td>24</td>\n",
       "      <td>15</td>\n",
       "      <td>49</td>\n",
       "      <td>384</td>\n",
       "      <td>39.09</td>\n",
       "      <td>73.02</td>\n",
       "      <td>0</td>\n",
       "      <td>7.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1250 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0  year  month  day  hour  min  sec    lat    lon  depth  ...  \\\n",
       "0              0  1980      2   15     9    9  350  40.54  78.31     -1  ...   \n",
       "1              1  1980      3   16     1   44   30  41.42  75.40     -1  ...   \n",
       "2              2  1980      7    5    20   25  220  41.46  77.30     20  ...   \n",
       "3              3  1980      8   31    23   38  372  40.52  77.46     -1  ...   \n",
       "4              4  1980      9    4     6   47  166  44.16  79.08     10  ...   \n",
       "...          ...   ...    ...  ...   ...  ...  ...    ...    ...    ...  ...   \n",
       "1245        1245  2013     12   12     0   46  471  44.12  81.18     10  ...   \n",
       "1246        1246  2013     12   18     1   44  283  41.00  78.45     15  ...   \n",
       "1247        1247  2013     12   21    14   21  464  37.12  71.31      0  ...   \n",
       "1248        1248  2013     12   22     7   45  314  38.22  72.07     20  ...   \n",
       "1249        1249  2013     12   24    12   40  316  39.10  73.27     10  ...   \n",
       "\n",
       "      year_as  month_as  day_as  hour_as  min_as  sec_as  lat_as  lon_as  \\\n",
       "0        1980         2      15        9      45     540   40.45   78.24   \n",
       "1        1980         3      25       10      58     236   41.40   75.42   \n",
       "2        1980         7       5       21      41     335   41.56   77.25   \n",
       "3        1980         9       4       22      56      92   40.51   77.37   \n",
       "4        1980         9      14        9      16     160   44.18   79.30   \n",
       "...       ...       ...     ...      ...     ...     ...     ...     ...   \n",
       "1245     2013        12      12        6       1     159   44.14   81.42   \n",
       "1246     2013        12      24       10       6     388   41.04   78.44   \n",
       "1247     2013        12      22        1      24      74   37.23   71.17   \n",
       "1248     2013        12      26        8      26     227   38.47   72.14   \n",
       "1249     2013        12      24       15      49     384   39.09   73.02   \n",
       "\n",
       "      depth_as  class_as  \n",
       "0           -1       7.7  \n",
       "1           -1       8.7  \n",
       "2            5       7.3  \n",
       "3           -1       7.3  \n",
       "4           -1       7.2  \n",
       "...        ...       ...  \n",
       "1245         5       6.2  \n",
       "1246        10       7.5  \n",
       "1247         5       9.3  \n",
       "1248         0       7.7  \n",
       "1249         0       7.1  \n",
       "\n",
       "[1250 rows x 21 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import datetime as dt\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv(\"./data/train.csv\", )\n",
    "\n",
    "X = data[['year', 'month', 'day', 'hour', 'min', 'sec', 'lat', 'lon', 'depth', 'class']].values\n",
    "y = data[['year_as', 'month_as', 'day_as', 'hour_as', 'min_as', 'sec_as', 'lat_as', 'lon_as', 'depth_as', 'class_as']].values\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ae3981fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "year",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "month",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "day",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "hour",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "min",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "sec",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "lat",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "lon",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "depth",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "class",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "year_as",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "month_as",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "day_as",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "hour_as",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "min_as",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "sec_as",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "lat_as",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "lon_as",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "depth_as",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "class_as",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "50d7828b-6acc-4767-90e1-4694a426ac3b",
       "rows": [
        [
         "0",
         "1980.0",
         "2.0",
         "15.0",
         "9.0",
         "9.0",
         "350.0",
         "40.54",
         "78.31",
         "-1.0",
         "12.0",
         "1980.0",
         "2.0",
         "15.0",
         "9.0",
         "45.0",
         "540.0",
         "40.45",
         "78.24",
         "-1.0",
         "7.7"
        ],
        [
         "1",
         "1980.0",
         "3.0",
         "16.0",
         "1.0",
         "44.0",
         "30.0",
         "41.42",
         "75.4",
         "-1.0",
         "10.4",
         "1980.0",
         "3.0",
         "25.0",
         "10.0",
         "58.0",
         "236.0",
         "41.4",
         "75.42",
         "-1.0",
         "8.7"
        ],
        [
         "2",
         "1980.0",
         "7.0",
         "5.0",
         "20.0",
         "25.0",
         "220.0",
         "41.46",
         "77.3",
         "20.0",
         "13.6",
         "1980.0",
         "7.0",
         "5.0",
         "21.0",
         "41.0",
         "335.0",
         "41.56",
         "77.25",
         "5.0",
         "7.3"
        ],
        [
         "3",
         "1980.0",
         "8.0",
         "31.0",
         "23.0",
         "38.0",
         "372.0",
         "40.52",
         "77.46",
         "-1.0",
         "11.9",
         "1980.0",
         "9.0",
         "4.0",
         "22.0",
         "56.0",
         "92.0",
         "40.51",
         "77.37",
         "-1.0",
         "7.3"
        ],
        [
         "4",
         "1980.0",
         "9.0",
         "4.0",
         "6.0",
         "47.0",
         "166.0",
         "44.16",
         "79.08",
         "10.0",
         "12.4",
         "1980.0",
         "9.0",
         "14.0",
         "9.0",
         "16.0",
         "160.0",
         "44.18",
         "79.3",
         "-1.0",
         "7.2"
        ],
        [
         "5",
         "1980.0",
         "9.0",
         "22.0",
         "15.0",
         "33.0",
         "552.0",
         "44.37",
         "79.4",
         "-1.0",
         "10.6",
         "1980.0",
         "9.0",
         "24.0",
         "10.0",
         "19.0",
         "232.0",
         "44.39",
         "79.3",
         "-1.0",
         "9.5"
        ],
        [
         "6",
         "1980.0",
         "9.0",
         "30.0",
         "0.0",
         "18.0",
         "388.0",
         "43.29",
         "75.13",
         "-1.0",
         "11.2",
         "1980.0",
         "9.0",
         "30.0",
         "9.0",
         "51.0",
         "60.0",
         "43.31",
         "75.08",
         "-1.0",
         "7.3"
        ],
        [
         "7",
         "1980.0",
         "10.0",
         "5.0",
         "14.0",
         "34.0",
         "292.0",
         "42.09",
         "76.39",
         "5.0",
         "10.1",
         "1980.0",
         "10.0",
         "19.0",
         "10.0",
         "7.0",
         "213.0",
         "42.17",
         "76.2",
         "-1.0",
         "7.3"
        ],
        [
         "8",
         "1980.0",
         "10.0",
         "7.0",
         "22.0",
         "49.0",
         "320.0",
         "40.07",
         "77.28",
         "-1.0",
         "11.9",
         "1980.0",
         "10.0",
         "9.0",
         "4.0",
         "28.0",
         "0.0",
         "40.34",
         "77.28",
         "-1.0",
         "8.0"
        ],
        [
         "9",
         "1980.0",
         "10.0",
         "19.0",
         "10.0",
         "52.0",
         "480.0",
         "44.21",
         "79.24",
         "-1.0",
         "11.8",
         "1980.0",
         "10.0",
         "19.0",
         "14.0",
         "33.0",
         "332.0",
         "44.18",
         "79.14",
         "-1.0",
         "8.9"
        ],
        [
         "10",
         "1980.0",
         "11.0",
         "5.0",
         "15.0",
         "22.0",
         "532.0",
         "42.16",
         "76.02",
         "15.0",
         "10.1",
         "1980.0",
         "11.0",
         "17.0",
         "0.0",
         "11.0",
         "108.0",
         "42.22",
         "76.04",
         "25.0",
         "9.2"
        ],
        [
         "11",
         "1980.0",
         "11.0",
         "14.0",
         "1.0",
         "48.0",
         "58.0",
         "41.39",
         "74.04",
         "22.0",
         "10.6",
         "1980.0",
         "11.0",
         "26.0",
         "14.0",
         "34.0",
         "328.0",
         "41.32",
         "74.08",
         "-1.0",
         "7.5"
        ],
        [
         "12",
         "1980.0",
         "12.0",
         "2.0",
         "18.0",
         "18.0",
         "592.0",
         "44.22",
         "80.5",
         "-1.0",
         "10.1",
         "1980.0",
         "12.0",
         "2.0",
         "19.0",
         "17.0",
         "300.0",
         "44.24",
         "80.51",
         "-1.0",
         "7.9"
        ],
        [
         "13",
         "1981.0",
         "1.0",
         "13.0",
         "2.0",
         "30.0",
         "486.0",
         "40.03",
         "77.28",
         "-1.0",
         "10.2",
         "1981.0",
         "1.0",
         "15.0",
         "22.0",
         "43.0",
         "300.0",
         "40.14",
         "77.32",
         "-1.0",
         "8.6"
        ],
        [
         "14",
         "1981.0",
         "2.0",
         "20.0",
         "10.0",
         "12.0",
         "380.0",
         "40.26",
         "76.53",
         "-1.0",
         "11.8",
         "1981.0",
         "3.0",
         "5.0",
         "4.0",
         "16.0",
         "590.0",
         "40.22",
         "76.55",
         "-1.0",
         "8.0"
        ],
        [
         "15",
         "1981.0",
         "2.0",
         "22.0",
         "16.0",
         "9.0",
         "228.0",
         "42.18",
         "76.25",
         "15.0",
         "10.3",
         "1981.0",
         "3.0",
         "3.0",
         "10.0",
         "5.0",
         "420.0",
         "42.08",
         "76.34",
         "-1.0",
         "8.4"
        ],
        [
         "16",
         "1981.0",
         "4.0",
         "9.0",
         "0.0",
         "35.0",
         "76.0",
         "41.49",
         "79.55",
         "-1.0",
         "10.5",
         "1981.0",
         "4.0",
         "10.0",
         "5.0",
         "24.0",
         "156.0",
         "41.58",
         "79.22",
         "-1.0",
         "9.1"
        ],
        [
         "17",
         "1981.0",
         "6.0",
         "1.0",
         "6.0",
         "1.0",
         "440.0",
         "41.0",
         "78.05",
         "-1.0",
         "11.7",
         "1981.0",
         "6.0",
         "1.0",
         "6.0",
         "49.0",
         "288.0",
         "41.0",
         "78.08",
         "-1.0",
         "7.7"
        ],
        [
         "18",
         "1981.0",
         "6.0",
         "13.0",
         "6.0",
         "14.0",
         "250.0",
         "41.2",
         "78.4",
         "-1.0",
         "10.8",
         "1981.0",
         "6.0",
         "22.0",
         "11.0",
         "28.0",
         "156.0",
         "41.06",
         "78.46",
         "-1.0",
         "8.4"
        ],
        [
         "19",
         "1981.0",
         "6.0",
         "25.0",
         "10.0",
         "21.0",
         "58.0",
         "40.23",
         "77.28",
         "-1.0",
         "11.0",
         "1981.0",
         "7.0",
         "2.0",
         "23.0",
         "22.0",
         "552.0",
         "40.26",
         "77.01",
         "-1.0",
         "9.2"
        ],
        [
         "20",
         "1981.0",
         "6.0",
         "30.0",
         "19.0",
         "32.0",
         "330.0",
         "43.06",
         "77.24",
         "15.0",
         "11.0",
         "1981.0",
         "7.0",
         "10.0",
         "10.0",
         "1.0",
         "395.0",
         "43.01",
         "77.19",
         "15.0",
         "5.4"
        ],
        [
         "21",
         "1981.0",
         "7.0",
         "29.0",
         "2.0",
         "14.0",
         "464.0",
         "41.16",
         "78.31",
         "-1.0",
         "10.2",
         "1981.0",
         "7.0",
         "29.0",
         "3.0",
         "39.0",
         "466.0",
         "41.16",
         "78.4",
         "-1.0",
         "7.9"
        ],
        [
         "22",
         "1981.0",
         "8.0",
         "6.0",
         "18.0",
         "30.0",
         "472.0",
         "40.17",
         "77.11",
         "-1.0",
         "11.4",
         "1981.0",
         "8.0",
         "6.0",
         "21.0",
         "7.0",
         "444.0",
         "40.28",
         "77.07",
         "-1.0",
         "7.9"
        ],
        [
         "23",
         "1981.0",
         "8.0",
         "30.0",
         "4.0",
         "4.0",
         "488.0",
         "42.48",
         "78.29",
         "10.0",
         "11.8",
         "1981.0",
         "8.0",
         "30.0",
         "4.0",
         "39.0",
         "296.0",
         "42.5",
         "78.27",
         "15.0",
         "8.2"
        ],
        [
         "24",
         "1981.0",
         "11.0",
         "4.0",
         "3.0",
         "54.0",
         "332.0",
         "40.57",
         "77.33",
         "-1.0",
         "10.3",
         "1981.0",
         "11.0",
         "13.0",
         "6.0",
         "39.0",
         "448.0",
         "40.41",
         "77.34",
         "-1.0",
         "9.6"
        ],
        [
         "25",
         "1981.0",
         "11.0",
         "10.0",
         "11.0",
         "28.0",
         "480.0",
         "43.55",
         "75.48",
         "-1.0",
         "10.8",
         "1981.0",
         "11.0",
         "10.0",
         "13.0",
         "31.0",
         "364.0",
         "43.55",
         "75.5",
         "10.0",
         "7.1"
        ],
        [
         "26",
         "1981.0",
         "12.0",
         "13.0",
         "17.0",
         "46.0",
         "56.0",
         "41.54",
         "78.28",
         "-1.0",
         "10.5",
         "1981.0",
         "12.0",
         "14.0",
         "0.0",
         "21.0",
         "92.0",
         "41.51",
         "78.24",
         "-1.0",
         "7.2"
        ],
        [
         "27",
         "1981.0",
         "12.0",
         "14.0",
         "13.0",
         "57.0",
         "44.0",
         "43.42",
         "78.03",
         "5.0",
         "10.1",
         "1981.0",
         "12.0",
         "18.0",
         "1.0",
         "32.0",
         "100.0",
         "43.27",
         "78.23",
         "-1.0",
         "6.4"
        ],
        [
         "28",
         "1981.0",
         "12.0",
         "18.0",
         "5.0",
         "46.0",
         "260.0",
         "40.08",
         "78.1",
         "-1.0",
         "11.5",
         "1981.0",
         "12.0",
         "22.0",
         "8.0",
         "54.0",
         "266.0",
         "40.26",
         "78.22",
         "-1.0",
         "8.1"
        ],
        [
         "29",
         "1981.0",
         "12.0",
         "24.0",
         "14.0",
         "7.0",
         "360.0",
         "40.1",
         "77.08",
         "-1.0",
         "12.0",
         "1981.0",
         "12.0",
         "26.0",
         "10.0",
         "33.0",
         "116.0",
         "40.3",
         "77.21",
         "-1.0",
         "8.8"
        ],
        [
         "30",
         "1982.0",
         "2.0",
         "1.0",
         "1.0",
         "29.0",
         "72.0",
         "41.51",
         "79.21",
         "-1.0",
         "11.2",
         "1982.0",
         "2.0",
         "5.0",
         "22.0",
         "54.0",
         "268.0",
         "41.46",
         "79.28",
         "-1.0",
         "7.8"
        ],
        [
         "31",
         "1982.0",
         "2.0",
         "23.0",
         "12.0",
         "23.0",
         "556.0",
         "40.36",
         "77.25",
         "-1.0",
         "12.0",
         "1982.0",
         "2.0",
         "23.0",
         "13.0",
         "28.0",
         "230.0",
         "40.39",
         "77.29",
         "-1.0",
         "7.9"
        ],
        [
         "32",
         "1982.0",
         "4.0",
         "3.0",
         "10.0",
         "26.0",
         "40.0",
         "40.16",
         "76.22",
         "-1.0",
         "11.6",
         "1982.0",
         "4.0",
         "10.0",
         "0.0",
         "23.0",
         "452.0",
         "40.27",
         "76.51",
         "-1.0",
         "7.1"
        ],
        [
         "33",
         "1982.0",
         "5.0",
         "18.0",
         "0.0",
         "42.0",
         "95.0",
         "40.23",
         "77.22",
         "-1.0",
         "10.3",
         "1982.0",
         "5.0",
         "20.0",
         "10.0",
         "1.0",
         "60.0",
         "40.2",
         "77.25",
         "-1.0",
         "9.3"
        ],
        [
         "34",
         "1982.0",
         "5.0",
         "19.0",
         "16.0",
         "33.0",
         "550.0",
         "40.58",
         "78.22",
         "-1.0",
         "12.2",
         "1982.0",
         "5.0",
         "19.0",
         "19.0",
         "13.0",
         "492.0",
         "40.45",
         "78.12",
         "-1.0",
         "7.2"
        ],
        [
         "35",
         "1982.0",
         "6.0",
         "2.0",
         "10.0",
         "5.0",
         "588.0",
         "42.42",
         "76.12",
         "20.0",
         "11.8",
         "1982.0",
         "6.0",
         "3.0",
         "8.0",
         "31.0",
         "390.0",
         "42.16",
         "76.07",
         "-1.0",
         "6.5"
        ],
        [
         "36",
         "1982.0",
         "8.0",
         "12.0",
         "1.0",
         "54.0",
         "540.0",
         "40.16",
         "77.42",
         "-1.0",
         "10.1",
         "1982.0",
         "8.0",
         "21.0",
         "3.0",
         "5.0",
         "202.0",
         "40.15",
         "77.14",
         "-1.0",
         "8.7"
        ],
        [
         "37",
         "1982.0",
         "8.0",
         "27.0",
         "23.0",
         "40.0",
         "20.0",
         "40.16",
         "77.2",
         "-1.0",
         "11.1",
         "1982.0",
         "8.0",
         "29.0",
         "19.0",
         "48.0",
         "72.0",
         "40.24",
         "77.06",
         "-1.0",
         "7.2"
        ],
        [
         "38",
         "1982.0",
         "11.0",
         "10.0",
         "21.0",
         "30.0",
         "200.0",
         "42.11",
         "76.28",
         "-1.0",
         "11.1",
         "1982.0",
         "11.0",
         "11.0",
         "13.0",
         "42.0",
         "380.0",
         "42.13",
         "76.16",
         "-1.0",
         "8.1"
        ],
        [
         "39",
         "1982.0",
         "12.0",
         "31.0",
         "2.0",
         "26.0",
         "10.0",
         "40.43",
         "78.16",
         "-1.0",
         "10.1",
         "1982.0",
         "12.0",
         "31.0",
         "2.0",
         "44.0",
         "324.0",
         "40.55",
         "78.23",
         "-1.0",
         "8.0"
        ],
        [
         "40",
         "1982.0",
         "12.0",
         "31.0",
         "19.0",
         "46.0",
         "464.0",
         "42.52",
         "77.22",
         "18.0",
         "13.7",
         "1982.0",
         "12.0",
         "31.0",
         "20.0",
         "47.0",
         "370.0",
         "42.47",
         "77.11",
         "-1.0",
         "6.2"
        ],
        [
         "41",
         "1983.0",
         "2.0",
         "13.0",
         "1.0",
         "40.0",
         "92.0",
         "40.08",
         "75.09",
         "-1.0",
         "14.6",
         "1983.0",
         "2.0",
         "13.0",
         "1.0",
         "52.0",
         "480.0",
         "40.06",
         "75.04",
         "-1.0",
         "13.6"
        ],
        [
         "42",
         "1983.0",
         "2.0",
         "13.0",
         "1.0",
         "52.0",
         "480.0",
         "40.06",
         "75.04",
         "-1.0",
         "13.6",
         "1983.0",
         "2.0",
         "13.0",
         "2.0",
         "2.0",
         "56.0",
         "40.06",
         "75.02",
         "-1.0",
         "11.0"
        ],
        [
         "43",
         "1983.0",
         "2.0",
         "13.0",
         "2.0",
         "2.0",
         "56.0",
         "40.06",
         "75.02",
         "-1.0",
         "11.0",
         "1983.0",
         "2.0",
         "13.0",
         "2.0",
         "6.0",
         "0.0",
         "40.06",
         "75.02",
         "-1.0",
         "10.6"
        ],
        [
         "44",
         "1983.0",
         "2.0",
         "13.0",
         "2.0",
         "12.0",
         "150.0",
         "40.0",
         "75.18",
         "-1.0",
         "11.9",
         "1983.0",
         "2.0",
         "13.0",
         "2.0",
         "17.0",
         "0.0",
         "40.0",
         "75.18",
         "-1.0",
         "10.9"
        ],
        [
         "45",
         "1983.0",
         "2.0",
         "13.0",
         "2.0",
         "22.0",
         "80.0",
         "40.0",
         "75.24",
         "-1.0",
         "11.1",
         "1983.0",
         "2.0",
         "13.0",
         "2.0",
         "31.0",
         "0.0",
         "40.06",
         "75.18",
         "-1.0",
         "9.9"
        ],
        [
         "46",
         "1983.0",
         "2.0",
         "13.0",
         "2.0",
         "38.0",
         "590.0",
         "40.0",
         "75.14",
         "-1.0",
         "12.5",
         "1983.0",
         "2.0",
         "13.0",
         "2.0",
         "44.0",
         "373.0",
         "40.0",
         "75.12",
         "-1.0",
         "9.1"
        ],
        [
         "47",
         "1983.0",
         "2.0",
         "13.0",
         "3.0",
         "54.0",
         "326.0",
         "40.06",
         "75.13",
         "-1.0",
         "11.0",
         "1983.0",
         "2.0",
         "13.0",
         "4.0",
         "1.0",
         "75.0",
         "40.13",
         "75.18",
         "-1.0",
         "9.1"
        ],
        [
         "48",
         "1983.0",
         "2.0",
         "13.0",
         "4.0",
         "5.0",
         "485.0",
         "40.09",
         "75.08",
         "-1.0",
         "10.6",
         "1983.0",
         "2.0",
         "13.0",
         "4.0",
         "14.0",
         "277.0",
         "40.0",
         "75.12",
         "-1.0",
         "8.0"
        ],
        [
         "49",
         "1983.0",
         "2.0",
         "13.0",
         "4.0",
         "18.0",
         "460.0",
         "40.05",
         "75.17",
         "-1.0",
         "11.6",
         "1983.0",
         "2.0",
         "13.0",
         "4.0",
         "23.0",
         "517.0",
         "40.04",
         "75.15",
         "-1.0",
         "11.0"
        ]
       ],
       "shape": {
        "columns": 20,
        "rows": 1250
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>min</th>\n",
       "      <th>sec</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>depth</th>\n",
       "      <th>class</th>\n",
       "      <th>year_as</th>\n",
       "      <th>month_as</th>\n",
       "      <th>day_as</th>\n",
       "      <th>hour_as</th>\n",
       "      <th>min_as</th>\n",
       "      <th>sec_as</th>\n",
       "      <th>lat_as</th>\n",
       "      <th>lon_as</th>\n",
       "      <th>depth_as</th>\n",
       "      <th>class_as</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1980.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>350.0</td>\n",
       "      <td>40.54</td>\n",
       "      <td>78.31</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1980.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>540.0</td>\n",
       "      <td>40.45</td>\n",
       "      <td>78.24</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>7.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1980.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>41.42</td>\n",
       "      <td>75.40</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>10.4</td>\n",
       "      <td>1980.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>236.0</td>\n",
       "      <td>41.40</td>\n",
       "      <td>75.42</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>8.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1980.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>41.46</td>\n",
       "      <td>77.30</td>\n",
       "      <td>20.0</td>\n",
       "      <td>13.6</td>\n",
       "      <td>1980.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>335.0</td>\n",
       "      <td>41.56</td>\n",
       "      <td>77.25</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1980.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>372.0</td>\n",
       "      <td>40.52</td>\n",
       "      <td>77.46</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>11.9</td>\n",
       "      <td>1980.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>40.51</td>\n",
       "      <td>77.37</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>7.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1980.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>44.16</td>\n",
       "      <td>79.08</td>\n",
       "      <td>10.0</td>\n",
       "      <td>12.4</td>\n",
       "      <td>1980.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>44.18</td>\n",
       "      <td>79.30</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>7.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1245</th>\n",
       "      <td>2013.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>471.0</td>\n",
       "      <td>44.12</td>\n",
       "      <td>81.18</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.9</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>159.0</td>\n",
       "      <td>44.14</td>\n",
       "      <td>81.42</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1246</th>\n",
       "      <td>2013.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>283.0</td>\n",
       "      <td>41.00</td>\n",
       "      <td>78.45</td>\n",
       "      <td>15.0</td>\n",
       "      <td>10.5</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>388.0</td>\n",
       "      <td>41.04</td>\n",
       "      <td>78.44</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1247</th>\n",
       "      <td>2013.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>464.0</td>\n",
       "      <td>37.12</td>\n",
       "      <td>71.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.5</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>37.23</td>\n",
       "      <td>71.17</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1248</th>\n",
       "      <td>2013.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>314.0</td>\n",
       "      <td>38.22</td>\n",
       "      <td>72.07</td>\n",
       "      <td>20.0</td>\n",
       "      <td>10.1</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>227.0</td>\n",
       "      <td>38.47</td>\n",
       "      <td>72.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1249</th>\n",
       "      <td>2013.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>316.0</td>\n",
       "      <td>39.10</td>\n",
       "      <td>73.27</td>\n",
       "      <td>10.0</td>\n",
       "      <td>11.4</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>384.0</td>\n",
       "      <td>39.09</td>\n",
       "      <td>73.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1250 rows Ã— 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        year  month   day  hour   min    sec    lat    lon  depth  class  \\\n",
       "0     1980.0    2.0  15.0   9.0   9.0  350.0  40.54  78.31   -1.0   12.0   \n",
       "1     1980.0    3.0  16.0   1.0  44.0   30.0  41.42  75.40   -1.0   10.4   \n",
       "2     1980.0    7.0   5.0  20.0  25.0  220.0  41.46  77.30   20.0   13.6   \n",
       "3     1980.0    8.0  31.0  23.0  38.0  372.0  40.52  77.46   -1.0   11.9   \n",
       "4     1980.0    9.0   4.0   6.0  47.0  166.0  44.16  79.08   10.0   12.4   \n",
       "...      ...    ...   ...   ...   ...    ...    ...    ...    ...    ...   \n",
       "1245  2013.0   12.0  12.0   0.0  46.0  471.0  44.12  81.18   10.0   10.9   \n",
       "1246  2013.0   12.0  18.0   1.0  44.0  283.0  41.00  78.45   15.0   10.5   \n",
       "1247  2013.0   12.0  21.0  14.0  21.0  464.0  37.12  71.31    0.0   11.5   \n",
       "1248  2013.0   12.0  22.0   7.0  45.0  314.0  38.22  72.07   20.0   10.1   \n",
       "1249  2013.0   12.0  24.0  12.0  40.0  316.0  39.10  73.27   10.0   11.4   \n",
       "\n",
       "      year_as  month_as  day_as  hour_as  min_as  sec_as  lat_as  lon_as  \\\n",
       "0      1980.0       2.0    15.0      9.0    45.0   540.0   40.45   78.24   \n",
       "1      1980.0       3.0    25.0     10.0    58.0   236.0   41.40   75.42   \n",
       "2      1980.0       7.0     5.0     21.0    41.0   335.0   41.56   77.25   \n",
       "3      1980.0       9.0     4.0     22.0    56.0    92.0   40.51   77.37   \n",
       "4      1980.0       9.0    14.0      9.0    16.0   160.0   44.18   79.30   \n",
       "...       ...       ...     ...      ...     ...     ...     ...     ...   \n",
       "1245   2013.0      12.0    12.0      6.0     1.0   159.0   44.14   81.42   \n",
       "1246   2013.0      12.0    24.0     10.0     6.0   388.0   41.04   78.44   \n",
       "1247   2013.0      12.0    22.0      1.0    24.0    74.0   37.23   71.17   \n",
       "1248   2013.0      12.0    26.0      8.0    26.0   227.0   38.47   72.14   \n",
       "1249   2013.0      12.0    24.0     15.0    49.0   384.0   39.09   73.02   \n",
       "\n",
       "      depth_as  class_as  \n",
       "0         -1.0       7.7  \n",
       "1         -1.0       8.7  \n",
       "2          5.0       7.3  \n",
       "3         -1.0       7.3  \n",
       "4         -1.0       7.2  \n",
       "...        ...       ...  \n",
       "1245       5.0       6.2  \n",
       "1246      10.0       7.5  \n",
       "1247       5.0       9.3  \n",
       "1248       0.0       7.7  \n",
       "1249       0.0       7.1  \n",
       "\n",
       "[1250 rows x 20 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df = pd.DataFrame()\n",
    "training_df[['year', 'month', 'day', 'hour', 'min', 'sec', 'lat', 'lon', 'depth', 'class']] = X\n",
    "training_df[['year_as', 'month_as', 'day_as', 'hour_as', 'min_as', 'sec_as', 'lat_as', 'lon_as', 'depth_as', 'class_as']] = y\n",
    "training_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "42dbb8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "from autogluon.common.utils.utils import setup_outputdir\n",
    "from autogluon.core.utils.loaders import load_pkl\n",
    "from autogluon.core.utils.savers import save_pkl\n",
    "import os.path\n",
    "\n",
    "class MultilabelPredictor:\n",
    "    \"\"\" Tabular Predictor for predicting multiple columns in table.\n",
    "        Creates multiple TabularPredictor objects which you can also use individually.\n",
    "        You can access the TabularPredictor for a particular label via: `multilabel_predictor.get_predictor(label_i)`\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        labels : List[str]\n",
    "            The ith element of this list is the column (i.e. `label`) predicted by the ith TabularPredictor stored in this object.\n",
    "        path : str, default = None\n",
    "            Path to directory where models and intermediate outputs should be saved.\n",
    "            If unspecified, a time-stamped folder called \"AutogluonModels/ag-[TIMESTAMP]\" will be created in the working directory to store all models.\n",
    "            Note: To call `fit()` twice and save all results of each fit, you must specify different `path` locations or don't specify `path` at all.\n",
    "            Otherwise files from first `fit()` will be overwritten by second `fit()`.\n",
    "            Caution: when predicting many labels, this directory may grow large as it needs to store many TabularPredictors.\n",
    "        problem_types : List[str], default = None\n",
    "            The ith element is the `problem_type` for the ith TabularPredictor stored in this object.\n",
    "        eval_metrics : List[str], default = None\n",
    "            The ith element is the `eval_metric` for the ith TabularPredictor stored in this object.\n",
    "        consider_labels_correlation : bool, default = True\n",
    "            Whether the predictions of multiple labels should account for label correlations or predict each label independently of the others.\n",
    "            If True, the ordering of `labels` may affect resulting accuracy as each label is predicted conditional on the previous labels appearing earlier in this list (i.e. in an auto-regressive fashion).\n",
    "            Set to False if during inference you may want to individually use just the ith TabularPredictor without predicting all the other labels.\n",
    "        kwargs :\n",
    "            Arguments passed into the initialization of each TabularPredictor.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    multi_predictor_file = 'multilabel_predictor.pkl'\n",
    "\n",
    "    def __init__(self, labels, path=None, problem_types=None, eval_metrics=None, consider_labels_correlation=True, **kwargs):\n",
    "        if len(labels) < 2:\n",
    "            raise ValueError(\"MultilabelPredictor is only intended for predicting MULTIPLE labels (columns), use TabularPredictor for predicting one label (column).\")\n",
    "        if (problem_types is not None) and (len(problem_types) != len(labels)):\n",
    "            raise ValueError(\"If provided, `problem_types` must have same length as `labels`\")\n",
    "        if (eval_metrics is not None) and (len(eval_metrics) != len(labels)):\n",
    "            raise ValueError(\"If provided, `eval_metrics` must have same length as `labels`\")\n",
    "        self.path = setup_outputdir(path, warn_if_exist=False)\n",
    "        self.labels = labels\n",
    "        self.consider_labels_correlation = consider_labels_correlation\n",
    "        self.predictors = {}  # key = label, value = TabularPredictor or str path to the TabularPredictor for this label\n",
    "        if eval_metrics is None:\n",
    "            self.eval_metrics = {}\n",
    "        else:\n",
    "            self.eval_metrics = {labels[i] : eval_metrics[i] for i in range(len(labels))}\n",
    "        problem_type = None\n",
    "        eval_metric = None\n",
    "        for i in range(len(labels)):\n",
    "            label = labels[i]\n",
    "            path_i = os.path.join(self.path, \"Predictor_\" + str(label))\n",
    "            if problem_types is not None:\n",
    "                problem_type = problem_types[i]\n",
    "            if eval_metrics is not None:\n",
    "                eval_metric = eval_metrics[i]\n",
    "            self.predictors[label] = TabularPredictor(label=label, problem_type=problem_type, eval_metric=eval_metric, path=path_i, **kwargs)\n",
    "\n",
    "    def fit(self, train_data, tuning_data=None, **kwargs):\n",
    "        \"\"\" Fits a separate TabularPredictor to predict each of the labels.\n",
    "\n",
    "            Parameters\n",
    "            ----------\n",
    "            train_data, tuning_data : str or pd.DataFrame\n",
    "                See documentation for `TabularPredictor.fit()`.\n",
    "            kwargs :\n",
    "                Arguments passed into the `fit()` call for each TabularPredictor.\n",
    "        \"\"\"\n",
    "        if isinstance(train_data, str):\n",
    "            train_data = TabularDataset(train_data)\n",
    "        if tuning_data is not None and isinstance(tuning_data, str):\n",
    "            tuning_data = TabularDataset(tuning_data)\n",
    "        train_data_og = train_data.copy()\n",
    "        if tuning_data is not None:\n",
    "            tuning_data_og = tuning_data.copy()\n",
    "        else:\n",
    "            tuning_data_og = None\n",
    "        save_metrics = len(self.eval_metrics) == 0\n",
    "        for i in range(len(self.labels)):\n",
    "            label = self.labels[i]\n",
    "            predictor = self.get_predictor(label)\n",
    "            if not self.consider_labels_correlation:\n",
    "                labels_to_drop = [l for l in self.labels if l != label]\n",
    "            else:\n",
    "                labels_to_drop = [self.labels[j] for j in range(i+1, len(self.labels))]\n",
    "            train_data = train_data_og.drop(labels_to_drop, axis=1)\n",
    "            if tuning_data is not None:\n",
    "                tuning_data = tuning_data_og.drop(labels_to_drop, axis=1)\n",
    "            print(f\"Fitting TabularPredictor for label: {label} ...\")\n",
    "            predictor.fit(train_data=train_data, tuning_data=tuning_data, **kwargs)\n",
    "            self.predictors[label] = predictor.path\n",
    "            if save_metrics:\n",
    "                self.eval_metrics[label] = predictor.eval_metric\n",
    "        self.save()\n",
    "\n",
    "    def predict(self, data, **kwargs):\n",
    "        \"\"\" Returns DataFrame with label columns containing predictions for each label.\n",
    "\n",
    "            Parameters\n",
    "            ----------\n",
    "            data : str or autogluon.tabular.TabularDataset or pd.DataFrame\n",
    "                Data to make predictions for. If label columns are present in this data, they will be ignored. See documentation for `TabularPredictor.predict()`.\n",
    "            kwargs :\n",
    "                Arguments passed into the predict() call for each TabularPredictor.\n",
    "        \"\"\"\n",
    "        return self._predict(data, as_proba=False, **kwargs)\n",
    "\n",
    "    def predict_proba(self, data, **kwargs):\n",
    "        \"\"\" Returns dict where each key is a label and the corresponding value is the `predict_proba()` output for just that label.\n",
    "\n",
    "            Parameters\n",
    "            ----------\n",
    "            data : str or autogluon.tabular.TabularDataset or pd.DataFrame\n",
    "                Data to make predictions for. See documentation for `TabularPredictor.predict()` and `TabularPredictor.predict_proba()`.\n",
    "            kwargs :\n",
    "                Arguments passed into the `predict_proba()` call for each TabularPredictor (also passed into a `predict()` call).\n",
    "        \"\"\"\n",
    "        return self._predict(data, as_proba=True, **kwargs)\n",
    "\n",
    "    def evaluate(self, data, **kwargs):\n",
    "        \"\"\" Returns dict where each key is a label and the corresponding value is the `evaluate()` output for just that label.\n",
    "\n",
    "            Parameters\n",
    "            ----------\n",
    "            data : str or autogluon.tabular.TabularDataset or pd.DataFrame\n",
    "                Data to evalate predictions of all labels for, must contain all labels as columns. See documentation for `TabularPredictor.evaluate()`.\n",
    "            kwargs :\n",
    "                Arguments passed into the `evaluate()` call for each TabularPredictor (also passed into the `predict()` call).\n",
    "        \"\"\"\n",
    "        data = self._get_data(data)\n",
    "        eval_dict = {}\n",
    "        for label in self.labels:\n",
    "            print(f\"Evaluating TabularPredictor for label: {label} ...\")\n",
    "            predictor = self.get_predictor(label)\n",
    "            eval_dict[label] = predictor.evaluate(data, **kwargs)\n",
    "            if self.consider_labels_correlation:\n",
    "                data[label] = predictor.predict(data, **kwargs)\n",
    "        return eval_dict\n",
    "\n",
    "    def save(self):\n",
    "        \"\"\" Save MultilabelPredictor to disk. \"\"\"\n",
    "        for label in self.labels:\n",
    "            if not isinstance(self.predictors[label], str):\n",
    "                self.predictors[label] = self.predictors[label].path\n",
    "        save_pkl.save(path=os.path.join(self.path, self.multi_predictor_file), object=self)\n",
    "        print(f\"MultilabelPredictor saved to disk. Load with: MultilabelPredictor.load('{self.path}')\")\n",
    "\n",
    "    @classmethod\n",
    "    def load(cls, path):\n",
    "        \"\"\" Load MultilabelPredictor from disk `path` previously specified when creating this MultilabelPredictor. \"\"\"\n",
    "        path = os.path.expanduser(path)\n",
    "        return load_pkl.load(path=os.path.join(path, cls.multi_predictor_file))\n",
    "\n",
    "    def get_predictor(self, label):\n",
    "        \"\"\" Returns TabularPredictor which is used to predict this label. \"\"\"\n",
    "        predictor = self.predictors[label]\n",
    "        if isinstance(predictor, str):\n",
    "            return TabularPredictor.load(path=predictor)\n",
    "        return predictor\n",
    "\n",
    "    def _get_data(self, data):\n",
    "        if isinstance(data, str):\n",
    "            return TabularDataset(data)\n",
    "        return data.copy()\n",
    "\n",
    "    def _predict(self, data, as_proba=False, **kwargs):\n",
    "        data = self._get_data(data)\n",
    "        if as_proba:\n",
    "            predproba_dict = {}\n",
    "        for label in self.labels:\n",
    "            print(f\"Predicting with TabularPredictor for label: {label} ...\")\n",
    "            predictor = self.get_predictor(label)\n",
    "            if as_proba:\n",
    "                predproba_dict[label] = predictor.predict_proba(data, as_multiclass=True, **kwargs)\n",
    "            data[label] = predictor.predict(data, **kwargs)\n",
    "        if not as_proba:\n",
    "            return data[self.labels]\n",
    "        else:\n",
    "            return predproba_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d311886b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels\\ag-20250412_194309\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.2\n",
      "Python Version:     3.10.6\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.26100\n",
      "CPU Count:          16\n",
      "Memory Avail:       16.21 GB / 63.92 GB (25.4%)\n",
      "Disk Space Avail:   122.30 GB / 1217.02 GB (10.0%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='experimental' : New in v1.2: Pre-trained foundation model + parallel fits. The absolute best accuracy without consideration for inference speed. Does not support GPU.\n",
      "\tpresets='best'         : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'         : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'         : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'       : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ... Time limit = 3600s\n",
      "AutoGluon will save models to \"c:\\Users\\Tora\\Downloads\\kbtu-data-science-challenge-2025-entry-task-new\\Final\\AutogluonModels\\ag-20250412_194309\\Predictor_year_as\"\n",
      "Train Data Rows:    1250\n",
      "Train Data Columns: 10\n",
      "Label Column:       year_as\n",
      "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == float, but few unique label-values observed and label-values can be converted to int).\n",
      "\tFirst 10 (of 34) unique label values:  [1980.0, 1981.0, 1982.0, 1983.0, 1984.0, 1985.0, 1986.0, 1987.0, 1988.0, 1989.0]\n",
      "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Train Data Class Count: 34\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    16609.76 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.10 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 10 | ['year', 'month', 'day', 'hour', 'min', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 10 | ['year', 'month', 'day', 'hour', 'min', ...]\n",
      "\t0.1s = Fit runtime\n",
      "\t10 features in original data used to generate 10 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.10 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.11s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 1000, Val Rows: 250\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}],\n",
      "\t'XGB': [{}],\n",
      "\t'FASTAI': [{}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting TabularPredictor for label: year_as ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting 13 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: KNeighborsUnif ... Training model for up to 3599.89s of the 3599.89s of remaining time.\n",
      "\t0.096\t = Validation score   (accuracy)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ... Training model for up to 3599.83s of the 3599.83s of remaining time.\n",
      "\t0.136\t = Validation score   (accuracy)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ... Training model for up to 3599.78s of the 3599.78s of remaining time.\n",
      "\t0.432\t = Validation score   (accuracy)\n",
      "\t1.56s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ... Training model for up to 3598.19s of the 3598.19s of remaining time.\n",
      "\t0.636\t = Validation score   (accuracy)\n",
      "\t5.7s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBM ... Training model for up to 3592.34s of the 3592.34s of remaining time.\n",
      "\t1.0\t = Validation score   (accuracy)\n",
      "\t3.05s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: RandomForestGini ... Training model for up to 3589.27s of the 3589.27s of remaining time.\n",
      "\t0.824\t = Validation score   (accuracy)\n",
      "\t1.62s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ... Training model for up to 3587.43s of the 3587.42s of remaining time.\n",
      "\t0.84\t = Validation score   (accuracy)\n",
      "\t1.49s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: CatBoost ... Training model for up to 3585.74s of the 3585.74s of remaining time.\n",
      "\t0.988\t = Validation score   (accuracy)\n",
      "\t37.09s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini ... Training model for up to 3548.61s of the 3548.61s of remaining time.\n",
      "\t0.836\t = Validation score   (accuracy)\n",
      "\t1.31s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr ... Training model for up to 3547.08s of the 3547.07s of remaining time.\n",
      "\t0.832\t = Validation score   (accuracy)\n",
      "\t1.34s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: XGBoost ... Training model for up to 3545.50s of the 3545.50s of remaining time.\n",
      "\t1.0\t = Validation score   (accuracy)\n",
      "\t2.42s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ... Training model for up to 3542.87s of the 3542.86s of remaining time.\n",
      "\t0.648\t = Validation score   (accuracy)\n",
      "\t59.4s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ... Training model for up to 3483.45s of the 3483.44s of remaining time.\n",
      "\t1.0\t = Validation score   (accuracy)\n",
      "\t11.09s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.00s of the 3472.25s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBM': 1.0}\n",
      "\t1.0\t = Validation score   (accuracy)\n",
      "\t0.14s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 127.97s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 23906.8 rows/s (250 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"c:\\Users\\Tora\\Downloads\\kbtu-data-science-challenge-2025-entry-task-new\\Final\\AutogluonModels\\ag-20250412_194309\\Predictor_year_as\")\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.2\n",
      "Python Version:     3.10.6\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.26100\n",
      "CPU Count:          16\n",
      "Memory Avail:       13.97 GB / 63.92 GB (21.9%)\n",
      "Disk Space Avail:   122.03 GB / 1217.02 GB (10.0%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='experimental' : New in v1.2: Pre-trained foundation model + parallel fits. The absolute best accuracy without consideration for inference speed. Does not support GPU.\n",
      "\tpresets='best'         : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'         : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'         : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'       : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ... Time limit = 3600s\n",
      "AutoGluon will save models to \"c:\\Users\\Tora\\Downloads\\kbtu-data-science-challenge-2025-entry-task-new\\Final\\AutogluonModels\\ag-20250412_194309\\Predictor_month_as\"\n",
      "Train Data Rows:    1250\n",
      "Train Data Columns: 11\n",
      "Label Column:       month_as\n",
      "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == float, but few unique label-values observed and label-values can be converted to int).\n",
      "\tFirst 10 (of 12) unique label values:  [2.0, 3.0, 7.0, 9.0, 10.0, 11.0, 12.0, 1.0, 4.0, 6.0]\n",
      "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Train Data Class Count: 12\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    14311.81 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.11 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 11 | ['year', 'month', 'day', 'hour', 'min', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 11 | ['year', 'month', 'day', 'hour', 'min', ...]\n",
      "\t0.1s = Fit runtime\n",
      "\t11 features in original data used to generate 11 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.11 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.08s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 1000, Val Rows: 250\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}],\n",
      "\t'XGB': [{}],\n",
      "\t'FASTAI': [{}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 13 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: KNeighborsUnif ... Training model for up to 3599.92s of the 3599.91s of remaining time.\n",
      "\t0.148\t = Validation score   (accuracy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting TabularPredictor for label: month_as ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t0.01s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ... Training model for up to 3599.87s of the 3599.87s of remaining time.\n",
      "\t0.14\t = Validation score   (accuracy)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ... Training model for up to 3599.82s of the 3599.82s of remaining time.\n",
      "\t0.772\t = Validation score   (accuracy)\n",
      "\t1.3s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ... Training model for up to 3598.48s of the 3598.48s of remaining time.\n",
      "\t0.828\t = Validation score   (accuracy)\n",
      "\t2.85s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBM ... Training model for up to 3595.58s of the 3595.58s of remaining time.\n",
      "\t0.932\t = Validation score   (accuracy)\n",
      "\t2.11s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: RandomForestGini ... Training model for up to 3593.42s of the 3593.42s of remaining time.\n",
      "\t0.856\t = Validation score   (accuracy)\n",
      "\t1.17s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ... Training model for up to 3592.07s of the 3592.07s of remaining time.\n",
      "\t0.884\t = Validation score   (accuracy)\n",
      "\t1.12s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: CatBoost ... Training model for up to 3590.79s of the 3590.79s of remaining time.\n",
      "\t0.924\t = Validation score   (accuracy)\n",
      "\t5.39s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini ... Training model for up to 3585.39s of the 3585.39s of remaining time.\n",
      "\t0.896\t = Validation score   (accuracy)\n",
      "\t1.09s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr ... Training model for up to 3584.13s of the 3584.13s of remaining time.\n",
      "\t0.912\t = Validation score   (accuracy)\n",
      "\t1.14s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: XGBoost ... Training model for up to 3582.81s of the 3582.81s of remaining time.\n",
      "\t0.928\t = Validation score   (accuracy)\n",
      "\t1.69s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ... Training model for up to 3581.03s of the 3581.03s of remaining time.\n",
      "\t0.892\t = Validation score   (accuracy)\n",
      "\t21.53s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ... Training model for up to 3559.49s of the 3559.49s of remaining time.\n",
      "\t0.932\t = Validation score   (accuracy)\n",
      "\t5.19s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.00s of the 3554.26s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBM': 0.667, 'NeuralNetFastAI': 0.333}\n",
      "\t0.936\t = Validation score   (accuracy)\n",
      "\t0.14s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 45.92s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 13870.1 rows/s (250 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"c:\\Users\\Tora\\Downloads\\kbtu-data-science-challenge-2025-entry-task-new\\Final\\AutogluonModels\\ag-20250412_194309\\Predictor_month_as\")\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.2\n",
      "Python Version:     3.10.6\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.26100\n",
      "CPU Count:          16\n",
      "Memory Avail:       14.09 GB / 63.92 GB (22.0%)\n",
      "Disk Space Avail:   121.91 GB / 1217.02 GB (10.0%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='experimental' : New in v1.2: Pre-trained foundation model + parallel fits. The absolute best accuracy without consideration for inference speed. Does not support GPU.\n",
      "\tpresets='best'         : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'         : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'         : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'       : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ... Time limit = 3600s\n",
      "AutoGluon will save models to \"c:\\Users\\Tora\\Downloads\\kbtu-data-science-challenge-2025-entry-task-new\\Final\\AutogluonModels\\ag-20250412_194309\\Predictor_day_as\"\n",
      "Train Data Rows:    1250\n",
      "Train Data Columns: 12\n",
      "Label Column:       day_as\n",
      "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == float, but few unique label-values observed and label-values can be converted to int).\n",
      "\tFirst 10 (of 31) unique label values:  [15.0, 25.0, 5.0, 4.0, 14.0, 24.0, 30.0, 19.0, 9.0, 17.0]\n",
      "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Train Data Class Count: 31\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    14423.84 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.11 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['year', 'month', 'day', 'hour', 'min', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['year', 'month', 'day', 'hour', 'min', ...]\n",
      "\t0.1s = Fit runtime\n",
      "\t12 features in original data used to generate 12 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.11 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.08s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 1000, Val Rows: 250\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}],\n",
      "\t'XGB': [{}],\n",
      "\t'FASTAI': [{}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 13 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: KNeighborsUnif ... Training model for up to 3599.92s of the 3599.91s of remaining time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting TabularPredictor for label: day_as ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t0.064\t = Validation score   (accuracy)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ... Training model for up to 3599.85s of the 3599.85s of remaining time.\n",
      "\t0.088\t = Validation score   (accuracy)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ... Training model for up to 3599.80s of the 3599.79s of remaining time.\n",
      "\t0.184\t = Validation score   (accuracy)\n",
      "\t1.39s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ... Training model for up to 3598.38s of the 3598.38s of remaining time.\n",
      "\t0.292\t = Validation score   (accuracy)\n",
      "\t5.18s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBM ... Training model for up to 3593.13s of the 3593.13s of remaining time.\n",
      "\t0.452\t = Validation score   (accuracy)\n",
      "\t4.8s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: RandomForestGini ... Training model for up to 3588.31s of the 3588.30s of remaining time.\n",
      "\t0.312\t = Validation score   (accuracy)\n",
      "\t1.65s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ... Training model for up to 3586.44s of the 3586.43s of remaining time.\n",
      "\t0.28\t = Validation score   (accuracy)\n",
      "\t1.67s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: CatBoost ... Training model for up to 3584.52s of the 3584.51s of remaining time.\n",
      "\t0.332\t = Validation score   (accuracy)\n",
      "\t17.33s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini ... Training model for up to 3567.17s of the 3567.16s of remaining time.\n",
      "\t0.288\t = Validation score   (accuracy)\n",
      "\t1.59s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr ... Training model for up to 3565.32s of the 3565.32s of remaining time.\n",
      "\t0.284\t = Validation score   (accuracy)\n",
      "\t1.63s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: XGBoost ... Training model for up to 3563.44s of the 3563.43s of remaining time.\n",
      "\t0.444\t = Validation score   (accuracy)\n",
      "\t3.73s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ... Training model for up to 3559.51s of the 3559.51s of remaining time.\n",
      "\t0.228\t = Validation score   (accuracy)\n",
      "\t11.4s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ... Training model for up to 3548.08s of the 3548.08s of remaining time.\n",
      "\t0.376\t = Validation score   (accuracy)\n",
      "\t12.73s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.00s of the 3534.56s of remaining time.\n",
      "\tEnsemble Weights: {'XGBoost': 0.7, 'LightGBM': 0.3}\n",
      "\t0.468\t = Validation score   (accuracy)\n",
      "\t0.13s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 65.62s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 19272.8 rows/s (250 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"c:\\Users\\Tora\\Downloads\\kbtu-data-science-challenge-2025-entry-task-new\\Final\\AutogluonModels\\ag-20250412_194309\\Predictor_day_as\")\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.2\n",
      "Python Version:     3.10.6\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.26100\n",
      "CPU Count:          16\n",
      "Memory Avail:       14.45 GB / 63.92 GB (22.6%)\n",
      "Disk Space Avail:   121.50 GB / 1217.02 GB (10.0%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='experimental' : New in v1.2: Pre-trained foundation model + parallel fits. The absolute best accuracy without consideration for inference speed. Does not support GPU.\n",
      "\tpresets='best'         : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'         : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'         : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'       : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ... Time limit = 3600s\n",
      "AutoGluon will save models to \"c:\\Users\\Tora\\Downloads\\kbtu-data-science-challenge-2025-entry-task-new\\Final\\AutogluonModels\\ag-20250412_194309\\Predictor_hour_as\"\n",
      "Train Data Rows:    1250\n",
      "Train Data Columns: 13\n",
      "Label Column:       hour_as\n",
      "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == float, but few unique label-values observed and label-values can be converted to int).\n",
      "\tFirst 10 (of 24) unique label values:  [9.0, 10.0, 21.0, 22.0, 4.0, 14.0, 0.0, 19.0, 5.0, 6.0]\n",
      "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Train Data Class Count: 24\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    14816.64 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.12 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 13 | ['year', 'month', 'day', 'hour', 'min', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 13 | ['year', 'month', 'day', 'hour', 'min', ...]\n",
      "\t0.1s = Fit runtime\n",
      "\t13 features in original data used to generate 13 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.12 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.12s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 1000, Val Rows: 250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting TabularPredictor for label: hour_as ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}],\n",
      "\t'XGB': [{}],\n",
      "\t'FASTAI': [{}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 13 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: KNeighborsUnif ... Training model for up to 3599.88s of the 3599.88s of remaining time.\n",
      "\t0.04\t = Validation score   (accuracy)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ... Training model for up to 3599.82s of the 3599.81s of remaining time.\n",
      "\t0.044\t = Validation score   (accuracy)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ... Training model for up to 3599.76s of the 3599.76s of remaining time.\n",
      "No improvement since epoch 3: early stopping\n",
      "\t0.088\t = Validation score   (accuracy)\n",
      "\t0.96s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ... Training model for up to 3598.77s of the 3598.76s of remaining time.\n",
      "\t0.152\t = Validation score   (accuracy)\n",
      "\t4.36s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBM ... Training model for up to 3594.37s of the 3594.37s of remaining time.\n",
      "\t0.18\t = Validation score   (accuracy)\n",
      "\t4.01s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: RandomForestGini ... Training model for up to 3590.35s of the 3590.34s of remaining time.\n",
      "\t0.108\t = Validation score   (accuracy)\n",
      "\t1.51s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ... Training model for up to 3588.59s of the 3588.59s of remaining time.\n",
      "\t0.128\t = Validation score   (accuracy)\n",
      "\t1.46s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: CatBoost ... Training model for up to 3586.90s of the 3586.90s of remaining time.\n",
      "\t0.12\t = Validation score   (accuracy)\n",
      "\t7.24s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini ... Training model for up to 3579.65s of the 3579.64s of remaining time.\n",
      "\t0.112\t = Validation score   (accuracy)\n",
      "\t1.27s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr ... Training model for up to 3578.15s of the 3578.15s of remaining time.\n",
      "\t0.12\t = Validation score   (accuracy)\n",
      "\t1.34s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: XGBoost ... Training model for up to 3576.59s of the 3576.58s of remaining time.\n",
      "\t0.164\t = Validation score   (accuracy)\n",
      "\t4.04s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ... Training model for up to 3572.38s of the 3572.38s of remaining time.\n",
      "\t0.084\t = Validation score   (accuracy)\n",
      "\t2.64s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ... Training model for up to 3569.72s of the 3569.71s of remaining time.\n",
      "\t0.152\t = Validation score   (accuracy)\n",
      "\t10.69s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.00s of the 3558.52s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBM': 0.571, 'XGBoost': 0.214, 'NeuralNetFastAI': 0.143, 'ExtraTreesEntr': 0.071}\n",
      "\t0.192\t = Validation score   (accuracy)\n",
      "\t0.12s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 41.66s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 2300.6 rows/s (250 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"c:\\Users\\Tora\\Downloads\\kbtu-data-science-challenge-2025-entry-task-new\\Final\\AutogluonModels\\ag-20250412_194309\\Predictor_hour_as\")\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.2\n",
      "Python Version:     3.10.6\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.26100\n",
      "CPU Count:          16\n",
      "Memory Avail:       14.45 GB / 63.92 GB (22.6%)\n",
      "Disk Space Avail:   121.15 GB / 1217.02 GB (10.0%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='experimental' : New in v1.2: Pre-trained foundation model + parallel fits. The absolute best accuracy without consideration for inference speed. Does not support GPU.\n",
      "\tpresets='best'         : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'         : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'         : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'       : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ... Time limit = 3600s\n",
      "AutoGluon will save models to \"c:\\Users\\Tora\\Downloads\\kbtu-data-science-challenge-2025-entry-task-new\\Final\\AutogluonModels\\ag-20250412_194309\\Predictor_min_as\"\n",
      "Train Data Rows:    1250\n",
      "Train Data Columns: 14\n",
      "Label Column:       min_as\n",
      "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == float, but few unique label-values observed and label-values can be converted to int).\n",
      "\tFirst 10 (of 60) unique label values:  [45.0, 58.0, 41.0, 56.0, 16.0, 19.0, 51.0, 7.0, 28.0, 33.0]\n",
      "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Train Data Class Count: 60\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    14791.93 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.13 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 14 | ['year', 'month', 'day', 'hour', 'min', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 14 | ['year', 'month', 'day', 'hour', 'min', ...]\n",
      "\t0.1s = Fit runtime\n",
      "\t14 features in original data used to generate 14 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.13 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.08s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 1000, Val Rows: 250\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}],\n",
      "\t'XGB': [{}],\n",
      "\t'FASTAI': [{}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 13 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: KNeighborsUnif ... Training model for up to 3599.92s of the 3599.92s of remaining time.\n",
      "\t0.024\t = Validation score   (accuracy)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ... Training model for up to 3599.88s of the 3599.87s of remaining time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting TabularPredictor for label: min_as ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t0.012\t = Validation score   (accuracy)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ... Training model for up to 3599.84s of the 3599.83s of remaining time.\n",
      "\t0.032\t = Validation score   (accuracy)\n",
      "\t1.26s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ... Training model for up to 3598.55s of the 3598.55s of remaining time.\n",
      "\t0.036\t = Validation score   (accuracy)\n",
      "\t7.88s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBM ... Training model for up to 3590.62s of the 3590.62s of remaining time.\n",
      "\t0.036\t = Validation score   (accuracy)\n",
      "\t6.32s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: RandomForestGini ... Training model for up to 3584.27s of the 3584.27s of remaining time.\n",
      "\t0.02\t = Validation score   (accuracy)\n",
      "\t2.32s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ... Training model for up to 3581.55s of the 3581.55s of remaining time.\n",
      "\t0.02\t = Validation score   (accuracy)\n",
      "\t2.19s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: CatBoost ... Training model for up to 3578.98s of the 3578.98s of remaining time.\n",
      "\t0.032\t = Validation score   (accuracy)\n",
      "\t15.08s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini ... Training model for up to 3563.89s of the 3563.89s of remaining time.\n",
      "\t0.012\t = Validation score   (accuracy)\n",
      "\t2.14s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr ... Training model for up to 3561.36s of the 3561.36s of remaining time.\n",
      "\t0.012\t = Validation score   (accuracy)\n",
      "\t2.04s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: XGBoost ... Training model for up to 3558.97s of the 3558.96s of remaining time.\n",
      "\t0.032\t = Validation score   (accuracy)\n",
      "\t6.85s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ... Training model for up to 3551.78s of the 3551.77s of remaining time.\n",
      "\t0.036\t = Validation score   (accuracy)\n",
      "\t3.1s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ... Training model for up to 3548.65s of the 3548.65s of remaining time.\n",
      "\t0.04\t = Validation score   (accuracy)\n",
      "\t19.23s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.00s of the 3529.35s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBMLarge': 0.923, 'NeuralNetFastAI': 0.077}\n",
      "\t0.044\t = Validation score   (accuracy)\n",
      "\t0.16s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 70.91s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 14140.5 rows/s (250 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"c:\\Users\\Tora\\Downloads\\kbtu-data-science-challenge-2025-entry-task-new\\Final\\AutogluonModels\\ag-20250412_194309\\Predictor_min_as\")\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.2\n",
      "Python Version:     3.10.6\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.26100\n",
      "CPU Count:          16\n",
      "Memory Avail:       14.40 GB / 63.92 GB (22.5%)\n",
      "Disk Space Avail:   120.41 GB / 1217.02 GB (9.9%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='experimental' : New in v1.2: Pre-trained foundation model + parallel fits. The absolute best accuracy without consideration for inference speed. Does not support GPU.\n",
      "\tpresets='best'         : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'         : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'         : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'       : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ... Time limit = 3600s\n",
      "AutoGluon will save models to \"c:\\Users\\Tora\\Downloads\\kbtu-data-science-challenge-2025-entry-task-new\\Final\\AutogluonModels\\ag-20250412_194309\\Predictor_sec_as\"\n",
      "Train Data Rows:    1250\n",
      "Train Data Columns: 15\n",
      "Label Column:       sec_as\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (600.0, 0.0, 289.8136, 175.46328)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    14745.60 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.14 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 15 | ['year', 'month', 'day', 'hour', 'min', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 15 | ['year', 'month', 'day', 'hour', 'min', ...]\n",
      "\t0.0s = Fit runtime\n",
      "\t15 features in original data used to generate 15 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.14 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.07s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 1000, Val Rows: 250\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}],\n",
      "\t'XGB': [{}],\n",
      "\t'FASTAI': [{}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 11 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: KNeighborsUnif ... Training model for up to 3599.93s of the 3599.92s of remaining time.\n",
      "\t-199.117\t = Validation score   (-root_mean_squared_error)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting TabularPredictor for label: sec_as ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t0.01s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ... Training model for up to 3599.88s of the 3599.87s of remaining time.\n",
      "\t-198.7409\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ... Training model for up to 3599.83s of the 3599.83s of remaining time.\n",
      "\t-184.4885\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.86s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBM ... Training model for up to 3598.96s of the 3598.95s of remaining time.\n",
      "\t-184.6193\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.9s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ... Training model for up to 3598.05s of the 3598.04s of remaining time.\n",
      "\t-193.5436\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.79s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: CatBoost ... Training model for up to 3597.10s of the 3597.10s of remaining time.\n",
      "\t-184.3917\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.59s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE ... Training model for up to 3596.51s of the 3596.50s of remaining time.\n",
      "\t-191.9055\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.67s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ... Training model for up to 3595.70s of the 3595.70s of remaining time.\n",
      "No improvement since epoch 1: early stopping\n",
      "\t-185.2998\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.85s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: XGBoost ... Training model for up to 3594.82s of the 3594.82s of remaining time.\n",
      "\t-184.9575\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.88s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ... Training model for up to 3593.92s of the 3593.91s of remaining time.\n",
      "\t-184.5057\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.28s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ... Training model for up to 3592.62s of the 3592.61s of remaining time.\n",
      "\t-184.494\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.68s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.00s of the 3590.91s of remaining time.\n",
      "\tEnsemble Weights: {'CatBoost': 1.0}\n",
      "\t-184.3917\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.04s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 9.16s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 163737.7 rows/s (250 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"c:\\Users\\Tora\\Downloads\\kbtu-data-science-challenge-2025-entry-task-new\\Final\\AutogluonModels\\ag-20250412_194309\\Predictor_sec_as\")\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.2\n",
      "Python Version:     3.10.6\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.26100\n",
      "CPU Count:          16\n",
      "Memory Avail:       14.41 GB / 63.92 GB (22.5%)\n",
      "Disk Space Avail:   120.36 GB / 1217.02 GB (9.9%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='experimental' : New in v1.2: Pre-trained foundation model + parallel fits. The absolute best accuracy without consideration for inference speed. Does not support GPU.\n",
      "\tpresets='best'         : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'         : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'         : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'       : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ... Time limit = 3600s\n",
      "AutoGluon will save models to \"c:\\Users\\Tora\\Downloads\\kbtu-data-science-challenge-2025-entry-task-new\\Final\\AutogluonModels\\ag-20250412_194309\\Predictor_lat_as\"\n",
      "Train Data Rows:    1250\n",
      "Train Data Columns: 16\n",
      "Label Column:       lat_as\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (48.05, 35.44, 41.0236, 1.90019)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    14743.72 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.15 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 16 | ['year', 'month', 'day', 'hour', 'min', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 16 | ['year', 'month', 'day', 'hour', 'min', ...]\n",
      "\t0.1s = Fit runtime\n",
      "\t16 features in original data used to generate 16 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.15 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.1s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 1000, Val Rows: 250\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}],\n",
      "\t'XGB': [{}],\n",
      "\t'FASTAI': [{}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 11 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: KNeighborsUnif ... Training model for up to 3599.90s of the 3599.89s of remaining time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting TabularPredictor for label: lat_as ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-1.9848\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.3s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ... Training model for up to 3599.58s of the 3599.57s of remaining time.\n",
      "\t-1.9803\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ... Training model for up to 3599.53s of the 3599.53s of remaining time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 0.257958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-0.2575\t = Validation score   (-root_mean_squared_error)\n",
      "\t3.25s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBM ... Training model for up to 3596.21s of the 3596.20s of remaining time.\n",
      "\t-0.1526\t = Validation score   (-root_mean_squared_error)\n",
      "\t2.55s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ... Training model for up to 3593.60s of the 3593.60s of remaining time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 0.153548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-0.1001\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.83s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: CatBoost ... Training model for up to 3592.62s of the 3592.62s of remaining time.\n",
      "\t-0.1639\t = Validation score   (-root_mean_squared_error)\n",
      "\t2.87s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE ... Training model for up to 3589.74s of the 3589.74s of remaining time.\n",
      "\t-0.0889\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.64s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ... Training model for up to 3588.96s of the 3588.96s of remaining time.\n",
      "\t-0.1656\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.12s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: XGBoost ... Training model for up to 3587.81s of the 3587.81s of remaining time.\n",
      "\t-0.1187\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.06s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ... Training model for up to 3586.72s of the 3586.72s of remaining time.\n",
      "\t-0.1372\t = Validation score   (-root_mean_squared_error)\n",
      "\t17.54s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ... Training model for up to 3569.16s of the 3569.16s of remaining time.\n",
      "\t-0.2107\t = Validation score   (-root_mean_squared_error)\n",
      "\t2.93s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.00s of the 3566.15s of remaining time.\n",
      "\tEnsemble Weights: {'ExtraTreesMSE': 0.867, 'NeuralNetFastAI': 0.067, 'NeuralNetTorch': 0.067}\n",
      "\t-0.0877\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.04s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 33.93s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 2416.4 rows/s (250 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"c:\\Users\\Tora\\Downloads\\kbtu-data-science-challenge-2025-entry-task-new\\Final\\AutogluonModels\\ag-20250412_194309\\Predictor_lat_as\")\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.2\n",
      "Python Version:     3.10.6\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.26100\n",
      "CPU Count:          16\n",
      "Memory Avail:       14.45 GB / 63.92 GB (22.6%)\n",
      "Disk Space Avail:   120.30 GB / 1217.02 GB (9.9%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='experimental' : New in v1.2: Pre-trained foundation model + parallel fits. The absolute best accuracy without consideration for inference speed. Does not support GPU.\n",
      "\tpresets='best'         : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'         : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'         : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'       : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ... Time limit = 3600s\n",
      "AutoGluon will save models to \"c:\\Users\\Tora\\Downloads\\kbtu-data-science-challenge-2025-entry-task-new\\Final\\AutogluonModels\\ag-20250412_194309\\Predictor_lon_as\"\n",
      "Train Data Rows:    1250\n",
      "Train Data Columns: 17\n",
      "Label Column:       lon_as\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (85.4, 67.23, 76.15453, 3.30136)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    14818.30 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.16 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 17 | ['year', 'month', 'day', 'hour', 'min', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 17 | ['year', 'month', 'day', 'hour', 'min', ...]\n",
      "\t0.1s = Fit runtime\n",
      "\t17 features in original data used to generate 17 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.16 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.09s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 1000, Val Rows: 250\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}],\n",
      "\t'XGB': [{}],\n",
      "\t'FASTAI': [{}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 11 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: KNeighborsUnif ... Training model for up to 3599.91s of the 3599.91s of remaining time.\n",
      "\t-3.5389\t = Validation score   (-root_mean_squared_error)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting TabularPredictor for label: lon_as ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t0.01s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ... Training model for up to 3599.87s of the 3599.87s of remaining time.\n",
      "\t-3.526\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ... Training model for up to 3599.81s of the 3599.80s of remaining time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 0.384335\n",
      "[2000]\tvalid_set's rmse: 0.383053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-0.3829\t = Validation score   (-root_mean_squared_error)\n",
      "\t6.43s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: LightGBM ... Training model for up to 3593.22s of the 3593.22s of remaining time.\n",
      "\t-0.2234\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.23s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ... Training model for up to 3591.97s of the 3591.97s of remaining time.\n",
      "\t-0.1653\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.76s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: CatBoost ... Training model for up to 3591.08s of the 3591.07s of remaining time.\n",
      "\t-0.2536\t = Validation score   (-root_mean_squared_error)\n",
      "\t2.08s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE ... Training model for up to 3588.99s of the 3588.99s of remaining time.\n",
      "\t-0.1654\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.67s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ... Training model for up to 3588.18s of the 3588.18s of remaining time.\n",
      "\t-0.278\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.16s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: XGBoost ... Training model for up to 3586.99s of the 3586.99s of remaining time.\n",
      "\t-0.1964\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.19s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ... Training model for up to 3585.77s of the 3585.77s of remaining time.\n",
      "\t-0.2528\t = Validation score   (-root_mean_squared_error)\n",
      "\t12.65s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ... Training model for up to 3573.10s of the 3573.10s of remaining time.\n",
      "\t-0.2805\t = Validation score   (-root_mean_squared_error)\n",
      "\t3.62s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.00s of the 3569.40s of remaining time.\n",
      "\tEnsemble Weights: {'RandomForestMSE': 0.524, 'ExtraTreesMSE': 0.238, 'XGBoost': 0.143, 'NeuralNetFastAI': 0.095}\n",
      "\t-0.16\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.04s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 30.67s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 1419.2 rows/s (250 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"c:\\Users\\Tora\\Downloads\\kbtu-data-science-challenge-2025-entry-task-new\\Final\\AutogluonModels\\ag-20250412_194309\\Predictor_lon_as\")\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.2\n",
      "Python Version:     3.10.6\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.26100\n",
      "CPU Count:          16\n",
      "Memory Avail:       14.37 GB / 63.92 GB (22.5%)\n",
      "Disk Space Avail:   120.24 GB / 1217.02 GB (9.9%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='experimental' : New in v1.2: Pre-trained foundation model + parallel fits. The absolute best accuracy without consideration for inference speed. Does not support GPU.\n",
      "\tpresets='best'         : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'         : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'         : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'       : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ... Time limit = 3600s\n",
      "AutoGluon will save models to \"c:\\Users\\Tora\\Downloads\\kbtu-data-science-challenge-2025-entry-task-new\\Final\\AutogluonModels\\ag-20250412_194309\\Predictor_depth_as\"\n",
      "Train Data Rows:    1250\n",
      "Train Data Columns: 18\n",
      "Label Column:       depth_as\n",
      "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == float, but few unique label-values observed and label-values can be converted to int).\n",
      "\tFirst 10 (of 18) unique label values:  [-1.0, 5.0, 25.0, 15.0, 10.0, 13.0, 8.0, 0.0, 20.0, 3.0]\n",
      "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Warning: Updated label_count_threshold from 10 to 9 to avoid cutting too many classes.\n",
      "Warning: Some classes in the training set have fewer than 9 examples. AutoGluon will only keep 9 out of 18 classes for training and will not try to predict the rare classes. To keep more classes, increase the number of datapoints from these rare classes in the training data or reduce label_count_threshold.\n",
      "Fraction of data from classes with at least 9 examples that will be kept for training models: 0.9752\n",
      "Train Data Class Count: 9\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    14706.16 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.17 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 18 | ['year', 'month', 'day', 'hour', 'min', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 18 | ['year', 'month', 'day', 'hour', 'min', ...]\n",
      "\t0.1s = Fit runtime\n",
      "\t18 features in original data used to generate 18 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.17 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.09s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 975, Val Rows: 244\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}],\n",
      "\t'XGB': [{}],\n",
      "\t'FASTAI': [{}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 13 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: KNeighborsUnif ... Training model for up to 3599.91s of the 3599.90s of remaining time.\n",
      "\t0.4631\t = Validation score   (accuracy)\n",
      "\t0.01s\t = Training   runtime\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting TabularPredictor for label: depth_as ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ... Training model for up to 3599.87s of the 3599.87s of remaining time.\n",
      "\t0.4344\t = Validation score   (accuracy)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ... Training model for up to 3599.84s of the 3599.83s of remaining time.\n",
      "\t0.6107\t = Validation score   (accuracy)\n",
      "\t1.34s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ... Training model for up to 3598.46s of the 3598.46s of remaining time.\n",
      "\t0.6107\t = Validation score   (accuracy)\n",
      "\t2.16s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBM ... Training model for up to 3596.27s of the 3596.27s of remaining time.\n",
      "\t0.6025\t = Validation score   (accuracy)\n",
      "\t2.38s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: RandomForestGini ... Training model for up to 3593.86s of the 3593.86s of remaining time.\n",
      "\t0.5902\t = Validation score   (accuracy)\n",
      "\t0.96s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ... Training model for up to 3592.76s of the 3592.76s of remaining time.\n",
      "\t0.5984\t = Validation score   (accuracy)\n",
      "\t0.93s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: CatBoost ... Training model for up to 3591.70s of the 3591.70s of remaining time.\n",
      "\t0.6352\t = Validation score   (accuracy)\n",
      "\t2.96s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini ... Training model for up to 3588.73s of the 3588.73s of remaining time.\n",
      "\t0.6025\t = Validation score   (accuracy)\n",
      "\t1.05s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr ... Training model for up to 3587.53s of the 3587.53s of remaining time.\n",
      "\t0.6025\t = Validation score   (accuracy)\n",
      "\t1.1s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: XGBoost ... Training model for up to 3586.27s of the 3586.27s of remaining time.\n",
      "\t0.6107\t = Validation score   (accuracy)\n",
      "\t2.05s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ... Training model for up to 3584.14s of the 3584.14s of remaining time.\n",
      "\t0.5984\t = Validation score   (accuracy)\n",
      "\t3.51s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ... Training model for up to 3580.61s of the 3580.61s of remaining time.\n",
      "\t0.6066\t = Validation score   (accuracy)\n",
      "\t4.82s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.00s of the 3575.63s of remaining time.\n",
      "\tEnsemble Weights: {'CatBoost': 0.857, 'RandomForestEntr': 0.143}\n",
      "\t0.6393\t = Validation score   (accuracy)\n",
      "\t0.12s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 24.53s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 2615.5 rows/s (244 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"c:\\Users\\Tora\\Downloads\\kbtu-data-science-challenge-2025-entry-task-new\\Final\\AutogluonModels\\ag-20250412_194309\\Predictor_depth_as\")\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.2\n",
      "Python Version:     3.10.6\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.26100\n",
      "CPU Count:          16\n",
      "Memory Avail:       14.32 GB / 63.92 GB (22.4%)\n",
      "Disk Space Avail:   120.15 GB / 1217.02 GB (9.9%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='experimental' : New in v1.2: Pre-trained foundation model + parallel fits. The absolute best accuracy without consideration for inference speed. Does not support GPU.\n",
      "\tpresets='best'         : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'         : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'         : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'       : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ... Time limit = 3600s\n",
      "AutoGluon will save models to \"c:\\Users\\Tora\\Downloads\\kbtu-data-science-challenge-2025-entry-task-new\\Final\\AutogluonModels\\ag-20250412_194309\\Predictor_class_as\"\n",
      "Train Data Rows:    1250\n",
      "Train Data Columns: 19\n",
      "Label Column:       class_as\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (15.2, 4.0, 8.298, 1.35047)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    14670.54 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.18 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 19 | ['year', 'month', 'day', 'hour', 'min', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 19 | ['year', 'month', 'day', 'hour', 'min', ...]\n",
      "\t0.1s = Fit runtime\n",
      "\t19 features in original data used to generate 19 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.18 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.11s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 1000, Val Rows: 250\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}],\n",
      "\t'XGB': [{}],\n",
      "\t'FASTAI': [{}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 11 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: KNeighborsUnif ... Training model for up to 3599.89s of the 3599.89s of remaining time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting TabularPredictor for label: class_as ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-1.4301\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ... Training model for up to 3599.85s of the 3599.85s of remaining time.\n",
      "\t-1.4262\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ... Training model for up to 3599.81s of the 3599.80s of remaining time.\n",
      "\t-1.0747\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.47s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBM ... Training model for up to 3598.31s of the 3598.31s of remaining time.\n",
      "\t-1.0838\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.12s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ... Training model for up to 3597.17s of the 3597.17s of remaining time.\n",
      "\t-1.1032\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.83s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: CatBoost ... Training model for up to 3596.20s of the 3596.20s of remaining time.\n",
      "\t-1.0797\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.35s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE ... Training model for up to 3594.84s of the 3594.84s of remaining time.\n",
      "\t-1.0707\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.67s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ... Training model for up to 3594.03s of the 3594.03s of remaining time.\n",
      "\t-1.1076\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.23s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: XGBoost ... Training model for up to 3592.77s of the 3592.77s of remaining time.\n",
      "\t-1.1226\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.24s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ... Training model for up to 3591.50s of the 3591.50s of remaining time.\n",
      "\t-1.1614\t = Validation score   (-root_mean_squared_error)\n",
      "\t4.18s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ... Training model for up to 3587.31s of the 3587.30s of remaining time.\n",
      "\t-1.1381\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.87s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.00s of the 3585.40s of remaining time.\n",
      "\tEnsemble Weights: {'ExtraTreesMSE': 0.375, 'LightGBMXT': 0.312, 'NeuralNetFastAI': 0.25, 'KNeighborsDist': 0.062}\n",
      "\t-1.0503\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.03s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 14.67s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 1903.4 rows/s (250 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"c:\\Users\\Tora\\Downloads\\kbtu-data-science-challenge-2025-entry-task-new\\Final\\AutogluonModels\\ag-20250412_194309\\Predictor_class_as\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultilabelPredictor saved to disk. Load with: MultilabelPredictor.load('c:\\Users\\Tora\\Downloads\\kbtu-data-science-challenge-2025-entry-task-new\\Final\\AutogluonModels\\ag-20250412_194309')\n"
     ]
    }
   ],
   "source": [
    "features_to_predict = ['year_as','month_as', 'day_as', 'hour_as', 'min_as', 'sec_as', 'lat_as', 'lon_as', 'depth_as', 'class_as']\n",
    "train_data = TabularDataset(training_df)\n",
    "\n",
    "multi_predictor = MultilabelPredictor(labels=features_to_predict)\n",
    "multi_predictor.fit(train_data, time_limit=3600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3575f936",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'WeightedEnsemble_L2'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.model_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2247cfe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Summary of fit() ***\n",
      "Estimated performance of each model:\n",
      "                   model  score_val         eval_metric  pred_time_val   fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0    WeightedEnsemble_L2  -1.339642  mean_squared_error       0.135309  46.273791                0.001626           0.123231            2       True          5\n",
      "1    WeightedEnsemble_L3  -1.339642  mean_squared_error       0.135323  46.273540                0.001640           0.122981            3       True          6\n",
      "2      LightGBMXT_BAG_L1  -1.370224  mean_squared_error       0.045309  46.127364                0.045309          46.127364            1       True          3\n",
      "3  KNeighborsUnif_BAG_L1  -1.592615  mean_squared_error       0.049263   0.011499                0.049263           0.011499            1       True          1\n",
      "4        LightGBM_BAG_L1  -1.781249  mean_squared_error       0.042126  23.680400                0.042126          23.680400            1       True          4\n",
      "5  KNeighborsDist_BAG_L1  -1.782378  mean_squared_error       0.039111   0.011696                0.039111           0.011696            1       True          2\n",
      "Number of models trained: 6\n",
      "Types of models trained:\n",
      "{'StackerEnsembleModel_KNN', 'StackerEnsembleModel_LGB', 'WeightedEnsembleModel'}\n",
      "Bagging used: True  (with 8 folds)\n",
      "Multi-layer stack-ensembling used: True  (with 3 levels)\n",
      "Feature Metadata (Processed):\n",
      "(raw dtype, special dtypes):\n",
      "('category', [])             :  7 | ['lat', 'lon', 'depth', 'class', 'lat_as', ...]\n",
      "('int', ['datetime_as_int']) : 10 | ['date', 'date.year', 'date.month', 'date.day', 'date.dayofweek', ...]\n",
      "*** End of fit() summary ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Tora\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\autogluon\\core\\utils\\plots.py:169: UserWarning: AutoGluon summary plots cannot be created because bokeh is not installed. To see plots, please do: \"pip install bokeh==2.0.1\"\n",
      "  warnings.warn('AutoGluon summary plots cannot be created because bokeh is not installed. To see plots, please do: \"pip install bokeh==2.0.1\"')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model_types': {'KNeighborsUnif_BAG_L1': 'StackerEnsembleModel_KNN',\n",
       "  'KNeighborsDist_BAG_L1': 'StackerEnsembleModel_KNN',\n",
       "  'LightGBMXT_BAG_L1': 'StackerEnsembleModel_LGB',\n",
       "  'LightGBM_BAG_L1': 'StackerEnsembleModel_LGB',\n",
       "  'WeightedEnsemble_L2': 'WeightedEnsembleModel',\n",
       "  'WeightedEnsemble_L3': 'WeightedEnsembleModel'},\n",
       " 'model_performance': {'KNeighborsUnif_BAG_L1': -1.5926150474146017,\n",
       "  'KNeighborsDist_BAG_L1': -1.7823775383088898,\n",
       "  'LightGBMXT_BAG_L1': -1.3702238643935303,\n",
       "  'LightGBM_BAG_L1': -1.7812491539460755,\n",
       "  'WeightedEnsemble_L2': -1.3396415668867747,\n",
       "  'WeightedEnsemble_L3': -1.3396415668867747},\n",
       " 'model_best': 'WeightedEnsemble_L2',\n",
       " 'model_paths': {'KNeighborsUnif_BAG_L1': ['KNeighborsUnif_BAG_L1'],\n",
       "  'KNeighborsDist_BAG_L1': ['KNeighborsDist_BAG_L1'],\n",
       "  'LightGBMXT_BAG_L1': ['LightGBMXT_BAG_L1'],\n",
       "  'LightGBM_BAG_L1': ['LightGBM_BAG_L1'],\n",
       "  'WeightedEnsemble_L2': ['WeightedEnsemble_L2'],\n",
       "  'WeightedEnsemble_L3': ['WeightedEnsemble_L3']},\n",
       " 'model_fit_times': {'KNeighborsUnif_BAG_L1': 0.01149892807006836,\n",
       "  'KNeighborsDist_BAG_L1': 0.011696100234985352,\n",
       "  'LightGBMXT_BAG_L1': 46.12736439704895,\n",
       "  'LightGBM_BAG_L1': 23.680400371551514,\n",
       "  'WeightedEnsemble_L2': 0.12323141098022461,\n",
       "  'WeightedEnsemble_L3': 0.12298059463500977},\n",
       " 'model_pred_times': {'KNeighborsUnif_BAG_L1': 0.04926252365112305,\n",
       "  'KNeighborsDist_BAG_L1': 0.03911137580871582,\n",
       "  'LightGBMXT_BAG_L1': 0.045308828353881836,\n",
       "  'LightGBM_BAG_L1': 0.042125701904296875,\n",
       "  'WeightedEnsemble_L2': 0.0016257762908935547,\n",
       "  'WeightedEnsemble_L3': 0.0016398429870605469},\n",
       " 'num_bag_folds': 8,\n",
       " 'max_stack_level': 3,\n",
       " 'model_hyperparams': {'KNeighborsUnif_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True,\n",
       "   'use_child_oof': True},\n",
       "  'KNeighborsDist_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True,\n",
       "   'use_child_oof': True},\n",
       "  'LightGBMXT_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'LightGBM_BAG_L1': {'use_orig_features': True,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'WeightedEnsemble_L2': {'use_orig_features': False,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True},\n",
       "  'WeightedEnsemble_L3': {'use_orig_features': False,\n",
       "   'valid_stacker': True,\n",
       "   'max_base_models': 0,\n",
       "   'max_base_models_per_type': 'auto',\n",
       "   'save_bag_folds': True}},\n",
       " 'leaderboard':                    model  score_val         eval_metric  pred_time_val  \\\n",
       " 0    WeightedEnsemble_L2  -1.339642  mean_squared_error       0.135309   \n",
       " 1    WeightedEnsemble_L3  -1.339642  mean_squared_error       0.135323   \n",
       " 2      LightGBMXT_BAG_L1  -1.370224  mean_squared_error       0.045309   \n",
       " 3  KNeighborsUnif_BAG_L1  -1.592615  mean_squared_error       0.049263   \n",
       " 4        LightGBM_BAG_L1  -1.781249  mean_squared_error       0.042126   \n",
       " 5  KNeighborsDist_BAG_L1  -1.782378  mean_squared_error       0.039111   \n",
       " \n",
       "     fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  \\\n",
       " 0  46.273791                0.001626           0.123231            2   \n",
       " 1  46.273540                0.001640           0.122981            3   \n",
       " 2  46.127364                0.045309          46.127364            1   \n",
       " 3   0.011499                0.049263           0.011499            1   \n",
       " 4  23.680400                0.042126          23.680400            1   \n",
       " 5   0.011696                0.039111           0.011696            1   \n",
       " \n",
       "    can_infer  fit_order  \n",
       " 0       True          5  \n",
       " 1       True          6  \n",
       " 2       True          3  \n",
       " 3       True          1  \n",
       " 4       True          4  \n",
       " 5       True          2  }"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.fit_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "51d310d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "id_eq",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "year",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "month",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "day",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "hour",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "min",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "sec",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "lat",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "lon",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "depth",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "class",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "b4df21ad-055c-46c0-b063-88bb6566134e",
       "rows": [
        [
         "0",
         "996",
         "2018",
         "2",
         "14",
         "23",
         "21",
         "505",
         "38.46",
         "73.45",
         "60",
         "10.7"
        ],
        [
         "1",
         "1336",
         "2020",
         "10",
         "2",
         "7",
         "16",
         "418",
         "37.22",
         "71.06",
         "20",
         "10.2"
        ],
        [
         "2",
         "730",
         "2016",
         "4",
         "15",
         "15",
         "21",
         "269",
         "51.05",
         "89.48",
         "10",
         "10.9"
        ],
        [
         "3",
         "696",
         "2016",
         "1",
         "26",
         "23",
         "19",
         "156",
         "37.18",
         "70.45",
         "0",
         "11.5"
        ],
        [
         "4",
         "1460",
         "2021",
         "10",
         "26",
         "17",
         "47",
         "43",
         "42.27",
         "83.46",
         "10",
         "11.0"
        ],
        [
         "5",
         "1636",
         "2023",
         "2",
         "10",
         "4",
         "40",
         "574",
         "37.13",
         "71.16",
         "15",
         "10.8"
        ],
        [
         "6",
         "728",
         "2016",
         "4",
         "10",
         "22",
         "14",
         "158",
         "37.43",
         "70.43",
         "0",
         "10.5"
        ],
        [
         "7",
         "1233",
         "2020",
         "1",
         "20",
         "5",
         "31",
         "37",
         "44.46",
         "78.48",
         "20",
         "11.2"
        ],
        [
         "8",
         "914",
         "2017",
         "5",
         "12",
         "16",
         "49",
         "82",
         "37.31",
         "71.53",
         "0",
         "10.8"
        ],
        [
         "9",
         "1324",
         "2020",
         "9",
         "1",
         "2",
         "56",
         "597",
         "37.22",
         "71.05",
         "0",
         "10.5"
        ],
        [
         "10",
         "1020",
         "2018",
         "4",
         "24",
         "15",
         "52",
         "94",
         "37.02",
         "70.44",
         "25",
         "12.1"
        ],
        [
         "11",
         "1436",
         "2021",
         "8",
         "29",
         "14",
         "27",
         "8",
         "43.44",
         "84.08",
         "10",
         "10.1"
        ],
        [
         "12",
         "1377",
         "2021",
         "1",
         "12",
         "13",
         "21",
         "596",
         "44.25",
         "80.12",
         "20",
         "11.2"
        ],
        [
         "13",
         "446",
         "2014",
         "1",
         "24",
         "18",
         "22",
         "412",
         "36.4",
         "71.34",
         "0",
         "10.2"
        ],
        [
         "14",
         "1067",
         "2018",
         "9",
         "14",
         "22",
         "15",
         "3",
         "41.55",
         "77.13",
         "5",
         "11.9"
        ],
        [
         "15",
         "876",
         "2017",
         "2",
         "22",
         "2",
         "22",
         "405",
         "40.16",
         "77.38",
         "5",
         "10.2"
        ],
        [
         "16",
         "920",
         "2017",
         "5",
         "26",
         "19",
         "9",
         "176",
         "39.3",
         "71.33",
         "5",
         "10.9"
        ],
        [
         "17",
         "1136",
         "2019",
         "4",
         "29",
         "0",
         "22",
         "427",
         "37.38",
         "73.26",
         "35",
         "11.8"
        ],
        [
         "18",
         "1731",
         "2023",
         "8",
         "6",
         "13",
         "23",
         "1",
         "37.24",
         "70.56",
         "5",
         "10.9"
        ],
        [
         "19",
         "1197",
         "2019",
         "10",
         "27",
         "10",
         "52",
         "393",
         "41.1",
         "78.49",
         "15",
         "11.6"
        ],
        [
         "20",
         "1699",
         "2023",
         "5",
         "27",
         "19",
         "24",
         "593",
         "37.19",
         "71.3",
         "30",
         "10.4"
        ],
        [
         "21",
         "573",
         "2015",
         "4",
         "12",
         "3",
         "24",
         "216",
         "38.54",
         "70.54",
         "25",
         "10.4"
        ],
        [
         "22",
         "1429",
         "2021",
         "7",
         "23",
         "20",
         "13",
         "2",
         "37.27",
         "71.18",
         "5",
         "10.6"
        ],
        [
         "23",
         "1620",
         "2023",
         "1",
         "9",
         "4",
         "48",
         "239",
         "37.2",
         "71.16",
         "5",
         "10.6"
        ],
        [
         "24",
         "743",
         "2016",
         "5",
         "5",
         "19",
         "54",
         "8",
         "41.16",
         "75.52",
         "15",
         "10.4"
        ],
        [
         "25",
         "474",
         "2014",
         "4",
         "24",
         "18",
         "34",
         "387",
         "42.58",
         "77.39",
         "15",
         "10.4"
        ],
        [
         "26",
         "1476",
         "2021",
         "12",
         "27",
         "18",
         "52",
         "3",
         "37.17",
         "71.26",
         "10",
         "10.6"
        ],
        [
         "27",
         "523",
         "2014",
         "9",
         "17",
         "6",
         "11",
         "407",
         "37.22",
         "71.37",
         "0",
         "10.2"
        ],
        [
         "28",
         "1529",
         "2022",
         "5",
         "24",
         "8",
         "23",
         "364",
         "37.01",
         "70.06",
         "20",
         "10.2"
        ],
        [
         "29",
         "1724",
         "2023",
         "7",
         "19",
         "7",
         "26",
         "462",
         "37.02",
         "70.09",
         "20",
         "11.8"
        ],
        [
         "30",
         "902",
         "2017",
         "4",
         "29",
         "13",
         "41",
         "483",
         "40.29",
         "74.47",
         "10",
         "10.8"
        ],
        [
         "31",
         "1719",
         "2023",
         "7",
         "3",
         "9",
         "14",
         "367",
         "36.56",
         "71.05",
         "95",
         "10.5"
        ],
        [
         "32",
         "776",
         "2016",
         "6",
         "30",
         "7",
         "9",
         "9",
         "38.4",
         "73.02",
         "5",
         "10.4"
        ],
        [
         "33",
         "1253",
         "2020",
         "3",
         "11",
         "7",
         "6",
         "561",
         "43.0",
         "80.0",
         "5",
         "10.8"
        ],
        [
         "34",
         "552",
         "2014",
         "12",
         "31",
         "19",
         "4",
         "569",
         "38.42",
         "72.31",
         "0",
         "11.4"
        ],
        [
         "35",
         "571",
         "2015",
         "3",
         "30",
         "4",
         "52",
         "44",
         "37.09",
         "70.57",
         "0",
         "10.3"
        ],
        [
         "36",
         "857",
         "2016",
         "12",
         "28",
         "14",
         "25",
         "504",
         "37.37",
         "70.55",
         "0",
         "11.7"
        ],
        [
         "37",
         "1293",
         "2020",
         "6",
         "6",
         "0",
         "10",
         "539",
         "44.55",
         "78.36",
         "15",
         "12.3"
        ],
        [
         "38",
         "884",
         "2017",
         "3",
         "13",
         "2",
         "7",
         "6",
         "37.39",
         "72.07",
         "10",
         "10.6"
        ],
        [
         "39",
         "1196",
         "2019",
         "10",
         "27",
         "5",
         "29",
         "442",
         "41.02",
         "78.48",
         "15",
         "12.8"
        ],
        [
         "40",
         "1651",
         "2023",
         "2",
         "28",
         "4",
         "21",
         "24",
         "38.14",
         "73.22",
         "10",
         "11.0"
        ],
        [
         "41",
         "1671",
         "2023",
         "4",
         "4",
         "20",
         "26",
         "511",
         "41.34",
         "81.05",
         "10",
         "10.2"
        ],
        [
         "42",
         "973",
         "2017",
         "11",
         "5",
         "1",
         "54",
         "259",
         "37.39",
         "71.18",
         "0",
         "10.8"
        ],
        [
         "43",
         "1441",
         "2021",
         "9",
         "4",
         "1",
         "54",
         "18",
         "37.39",
         "77.34",
         "20",
         "11.6"
        ],
        [
         "44",
         "676",
         "2015",
         "12",
         "26",
         "14",
         "19",
         "7",
         "42.06",
         "83.56",
         "0",
         "10.3"
        ],
        [
         "45",
         "1118",
         "2019",
         "1",
         "29",
         "19",
         "10",
         "277",
         "37.46",
         "71.12",
         "20",
         "10.2"
        ],
        [
         "46",
         "1562",
         "2022",
         "8",
         "4",
         "19",
         "8",
         "183",
         "37.2",
         "71.3",
         "10",
         "10.7"
        ],
        [
         "47",
         "716",
         "2016",
         "3",
         "20",
         "0",
         "19",
         "93",
         "37.1",
         "71.27",
         "0",
         "11.2"
        ],
        [
         "48",
         "1014",
         "2018",
         "4",
         "8",
         "16",
         "12",
         "569",
         "42.58",
         "78.19",
         "10",
         "10.2"
        ],
        [
         "49",
         "1599",
         "2022",
         "11",
         "27",
         "19",
         "58",
         "415",
         "39.45",
         "74.44",
         "20",
         "11.7"
        ]
       ],
       "shape": {
        "columns": 11,
        "rows": 300
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_eq</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>min</th>\n",
       "      <th>sec</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>depth</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>996</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>23</td>\n",
       "      <td>21</td>\n",
       "      <td>505</td>\n",
       "      <td>38.46</td>\n",
       "      <td>73.45</td>\n",
       "      <td>60</td>\n",
       "      <td>10.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1336</td>\n",
       "      <td>2020</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "      <td>418</td>\n",
       "      <td>37.22</td>\n",
       "      <td>71.06</td>\n",
       "      <td>20</td>\n",
       "      <td>10.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>730</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>21</td>\n",
       "      <td>269</td>\n",
       "      <td>51.05</td>\n",
       "      <td>89.48</td>\n",
       "      <td>10</td>\n",
       "      <td>10.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>696</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>23</td>\n",
       "      <td>19</td>\n",
       "      <td>156</td>\n",
       "      <td>37.18</td>\n",
       "      <td>70.45</td>\n",
       "      <td>0</td>\n",
       "      <td>11.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1460</td>\n",
       "      <td>2021</td>\n",
       "      <td>10</td>\n",
       "      <td>26</td>\n",
       "      <td>17</td>\n",
       "      <td>47</td>\n",
       "      <td>43</td>\n",
       "      <td>42.27</td>\n",
       "      <td>83.46</td>\n",
       "      <td>10</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>1422</td>\n",
       "      <td>2021</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>421</td>\n",
       "      <td>38.44</td>\n",
       "      <td>70.27</td>\n",
       "      <td>10</td>\n",
       "      <td>13.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>737</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>27</td>\n",
       "      <td>10</td>\n",
       "      <td>54</td>\n",
       "      <td>2</td>\n",
       "      <td>37.53</td>\n",
       "      <td>71.42</td>\n",
       "      <td>25</td>\n",
       "      <td>10.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>1737</td>\n",
       "      <td>2023</td>\n",
       "      <td>8</td>\n",
       "      <td>21</td>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "      <td>104</td>\n",
       "      <td>37.26</td>\n",
       "      <td>71.29</td>\n",
       "      <td>5</td>\n",
       "      <td>10.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>1184</td>\n",
       "      <td>2019</td>\n",
       "      <td>9</td>\n",
       "      <td>29</td>\n",
       "      <td>22</td>\n",
       "      <td>47</td>\n",
       "      <td>449</td>\n",
       "      <td>37.15</td>\n",
       "      <td>71.00</td>\n",
       "      <td>10</td>\n",
       "      <td>10.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>503</td>\n",
       "      <td>2014</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "      <td>17</td>\n",
       "      <td>294</td>\n",
       "      <td>41.03</td>\n",
       "      <td>78.39</td>\n",
       "      <td>0</td>\n",
       "      <td>10.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     id_eq  year  month  day  hour  min  sec    lat    lon  depth  class\n",
       "0      996  2018      2   14    23   21  505  38.46  73.45     60   10.7\n",
       "1     1336  2020     10    2     7   16  418  37.22  71.06     20   10.2\n",
       "2      730  2016      4   15    15   21  269  51.05  89.48     10   10.9\n",
       "3      696  2016      1   26    23   19  156  37.18  70.45      0   11.5\n",
       "4     1460  2021     10   26    17   47   43  42.27  83.46     10   11.0\n",
       "..     ...   ...    ...  ...   ...  ...  ...    ...    ...    ...    ...\n",
       "295   1422  2021      7   10     2   14  421  38.44  70.27     10   13.4\n",
       "296    737  2016      4   27    10   54    2  37.53  71.42     25   10.2\n",
       "297   1737  2023      8   21     4   40  104  37.26  71.29      5   10.7\n",
       "298   1184  2019      9   29    22   47  449  37.15  71.00     10   10.3\n",
       "299    503  2014      8   13     8   17  294  41.03  78.39      0   10.7\n",
       "\n",
       "[300 rows x 11 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import datetime as dt\n",
    "\n",
    "# Load the dataset\n",
    "data_t = pd.read_csv(\"./data/test.csv\", )\n",
    "\n",
    "X = data_t[['year', 'month', 'day', 'hour', 'min', 'sec', 'lat', 'lon', 'depth', 'class']].values\n",
    "\n",
    "data_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5f1e5d9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "year",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "month",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "day",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "hour",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "min",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "sec",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "lat",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "lon",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "depth",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "class",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "year_as",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "month_as",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "day_as",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "hour_as",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "min_as",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "sec_as",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "lat_as",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "lon_as",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "depth_as",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "class_as",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "ac2f15f7-9e0b-400e-a9c3-77747d8e9a46",
       "rows": [
        [
         "0",
         "2018.0",
         "2.0",
         "14.0",
         "23.0",
         "21.0",
         "505.0",
         "38.46",
         "73.45",
         "60.0",
         "10.7",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "1",
         "2020.0",
         "10.0",
         "2.0",
         "7.0",
         "16.0",
         "418.0",
         "37.22",
         "71.06",
         "20.0",
         "10.2",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "2",
         "2016.0",
         "4.0",
         "15.0",
         "15.0",
         "21.0",
         "269.0",
         "51.05",
         "89.48",
         "10.0",
         "10.9",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "3",
         "2016.0",
         "1.0",
         "26.0",
         "23.0",
         "19.0",
         "156.0",
         "37.18",
         "70.45",
         "0.0",
         "11.5",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "4",
         "2021.0",
         "10.0",
         "26.0",
         "17.0",
         "47.0",
         "43.0",
         "42.27",
         "83.46",
         "10.0",
         "11.0",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "5",
         "2023.0",
         "2.0",
         "10.0",
         "4.0",
         "40.0",
         "574.0",
         "37.13",
         "71.16",
         "15.0",
         "10.8",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "6",
         "2016.0",
         "4.0",
         "10.0",
         "22.0",
         "14.0",
         "158.0",
         "37.43",
         "70.43",
         "0.0",
         "10.5",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "7",
         "2020.0",
         "1.0",
         "20.0",
         "5.0",
         "31.0",
         "37.0",
         "44.46",
         "78.48",
         "20.0",
         "11.2",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "8",
         "2017.0",
         "5.0",
         "12.0",
         "16.0",
         "49.0",
         "82.0",
         "37.31",
         "71.53",
         "0.0",
         "10.8",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "9",
         "2020.0",
         "9.0",
         "1.0",
         "2.0",
         "56.0",
         "597.0",
         "37.22",
         "71.05",
         "0.0",
         "10.5",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "10",
         "2018.0",
         "4.0",
         "24.0",
         "15.0",
         "52.0",
         "94.0",
         "37.02",
         "70.44",
         "25.0",
         "12.1",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "11",
         "2021.0",
         "8.0",
         "29.0",
         "14.0",
         "27.0",
         "8.0",
         "43.44",
         "84.08",
         "10.0",
         "10.1",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "12",
         "2021.0",
         "1.0",
         "12.0",
         "13.0",
         "21.0",
         "596.0",
         "44.25",
         "80.12",
         "20.0",
         "11.2",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "13",
         "2014.0",
         "1.0",
         "24.0",
         "18.0",
         "22.0",
         "412.0",
         "36.4",
         "71.34",
         "0.0",
         "10.2",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "14",
         "2018.0",
         "9.0",
         "14.0",
         "22.0",
         "15.0",
         "3.0",
         "41.55",
         "77.13",
         "5.0",
         "11.9",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "15",
         "2017.0",
         "2.0",
         "22.0",
         "2.0",
         "22.0",
         "405.0",
         "40.16",
         "77.38",
         "5.0",
         "10.2",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "16",
         "2017.0",
         "5.0",
         "26.0",
         "19.0",
         "9.0",
         "176.0",
         "39.3",
         "71.33",
         "5.0",
         "10.9",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "17",
         "2019.0",
         "4.0",
         "29.0",
         "0.0",
         "22.0",
         "427.0",
         "37.38",
         "73.26",
         "35.0",
         "11.8",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "18",
         "2023.0",
         "8.0",
         "6.0",
         "13.0",
         "23.0",
         "1.0",
         "37.24",
         "70.56",
         "5.0",
         "10.9",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "19",
         "2019.0",
         "10.0",
         "27.0",
         "10.0",
         "52.0",
         "393.0",
         "41.1",
         "78.49",
         "15.0",
         "11.6",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "20",
         "2023.0",
         "5.0",
         "27.0",
         "19.0",
         "24.0",
         "593.0",
         "37.19",
         "71.3",
         "30.0",
         "10.4",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "21",
         "2015.0",
         "4.0",
         "12.0",
         "3.0",
         "24.0",
         "216.0",
         "38.54",
         "70.54",
         "25.0",
         "10.4",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "22",
         "2021.0",
         "7.0",
         "23.0",
         "20.0",
         "13.0",
         "2.0",
         "37.27",
         "71.18",
         "5.0",
         "10.6",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "23",
         "2023.0",
         "1.0",
         "9.0",
         "4.0",
         "48.0",
         "239.0",
         "37.2",
         "71.16",
         "5.0",
         "10.6",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "24",
         "2016.0",
         "5.0",
         "5.0",
         "19.0",
         "54.0",
         "8.0",
         "41.16",
         "75.52",
         "15.0",
         "10.4",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "25",
         "2014.0",
         "4.0",
         "24.0",
         "18.0",
         "34.0",
         "387.0",
         "42.58",
         "77.39",
         "15.0",
         "10.4",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "26",
         "2021.0",
         "12.0",
         "27.0",
         "18.0",
         "52.0",
         "3.0",
         "37.17",
         "71.26",
         "10.0",
         "10.6",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "27",
         "2014.0",
         "9.0",
         "17.0",
         "6.0",
         "11.0",
         "407.0",
         "37.22",
         "71.37",
         "0.0",
         "10.2",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "28",
         "2022.0",
         "5.0",
         "24.0",
         "8.0",
         "23.0",
         "364.0",
         "37.01",
         "70.06",
         "20.0",
         "10.2",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "29",
         "2023.0",
         "7.0",
         "19.0",
         "7.0",
         "26.0",
         "462.0",
         "37.02",
         "70.09",
         "20.0",
         "11.8",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "30",
         "2017.0",
         "4.0",
         "29.0",
         "13.0",
         "41.0",
         "483.0",
         "40.29",
         "74.47",
         "10.0",
         "10.8",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "31",
         "2023.0",
         "7.0",
         "3.0",
         "9.0",
         "14.0",
         "367.0",
         "36.56",
         "71.05",
         "95.0",
         "10.5",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "32",
         "2016.0",
         "6.0",
         "30.0",
         "7.0",
         "9.0",
         "9.0",
         "38.4",
         "73.02",
         "5.0",
         "10.4",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "33",
         "2020.0",
         "3.0",
         "11.0",
         "7.0",
         "6.0",
         "561.0",
         "43.0",
         "80.0",
         "5.0",
         "10.8",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "34",
         "2014.0",
         "12.0",
         "31.0",
         "19.0",
         "4.0",
         "569.0",
         "38.42",
         "72.31",
         "0.0",
         "11.4",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "35",
         "2015.0",
         "3.0",
         "30.0",
         "4.0",
         "52.0",
         "44.0",
         "37.09",
         "70.57",
         "0.0",
         "10.3",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "36",
         "2016.0",
         "12.0",
         "28.0",
         "14.0",
         "25.0",
         "504.0",
         "37.37",
         "70.55",
         "0.0",
         "11.7",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "37",
         "2020.0",
         "6.0",
         "6.0",
         "0.0",
         "10.0",
         "539.0",
         "44.55",
         "78.36",
         "15.0",
         "12.3",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "38",
         "2017.0",
         "3.0",
         "13.0",
         "2.0",
         "7.0",
         "6.0",
         "37.39",
         "72.07",
         "10.0",
         "10.6",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "39",
         "2019.0",
         "10.0",
         "27.0",
         "5.0",
         "29.0",
         "442.0",
         "41.02",
         "78.48",
         "15.0",
         "12.8",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "40",
         "2023.0",
         "2.0",
         "28.0",
         "4.0",
         "21.0",
         "24.0",
         "38.14",
         "73.22",
         "10.0",
         "11.0",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "41",
         "2023.0",
         "4.0",
         "4.0",
         "20.0",
         "26.0",
         "511.0",
         "41.34",
         "81.05",
         "10.0",
         "10.2",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "42",
         "2017.0",
         "11.0",
         "5.0",
         "1.0",
         "54.0",
         "259.0",
         "37.39",
         "71.18",
         "0.0",
         "10.8",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "43",
         "2021.0",
         "9.0",
         "4.0",
         "1.0",
         "54.0",
         "18.0",
         "37.39",
         "77.34",
         "20.0",
         "11.6",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "44",
         "2015.0",
         "12.0",
         "26.0",
         "14.0",
         "19.0",
         "7.0",
         "42.06",
         "83.56",
         "0.0",
         "10.3",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "45",
         "2019.0",
         "1.0",
         "29.0",
         "19.0",
         "10.0",
         "277.0",
         "37.46",
         "71.12",
         "20.0",
         "10.2",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "46",
         "2022.0",
         "8.0",
         "4.0",
         "19.0",
         "8.0",
         "183.0",
         "37.2",
         "71.3",
         "10.0",
         "10.7",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "47",
         "2016.0",
         "3.0",
         "20.0",
         "0.0",
         "19.0",
         "93.0",
         "37.1",
         "71.27",
         "0.0",
         "11.2",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "48",
         "2018.0",
         "4.0",
         "8.0",
         "16.0",
         "12.0",
         "569.0",
         "42.58",
         "78.19",
         "10.0",
         "10.2",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "49",
         "2022.0",
         "11.0",
         "27.0",
         "19.0",
         "58.0",
         "415.0",
         "39.45",
         "74.44",
         "20.0",
         "11.7",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null
        ]
       ],
       "shape": {
        "columns": 20,
        "rows": 300
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>min</th>\n",
       "      <th>sec</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>depth</th>\n",
       "      <th>class</th>\n",
       "      <th>year_as</th>\n",
       "      <th>month_as</th>\n",
       "      <th>day_as</th>\n",
       "      <th>hour_as</th>\n",
       "      <th>min_as</th>\n",
       "      <th>sec_as</th>\n",
       "      <th>lat_as</th>\n",
       "      <th>lon_as</th>\n",
       "      <th>depth_as</th>\n",
       "      <th>class_as</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>505.0</td>\n",
       "      <td>38.46</td>\n",
       "      <td>73.45</td>\n",
       "      <td>60.0</td>\n",
       "      <td>10.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>418.0</td>\n",
       "      <td>37.22</td>\n",
       "      <td>71.06</td>\n",
       "      <td>20.0</td>\n",
       "      <td>10.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>269.0</td>\n",
       "      <td>51.05</td>\n",
       "      <td>89.48</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>37.18</td>\n",
       "      <td>70.45</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>42.27</td>\n",
       "      <td>83.46</td>\n",
       "      <td>10.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>2021.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>421.0</td>\n",
       "      <td>38.44</td>\n",
       "      <td>70.27</td>\n",
       "      <td>10.0</td>\n",
       "      <td>13.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>37.53</td>\n",
       "      <td>71.42</td>\n",
       "      <td>25.0</td>\n",
       "      <td>10.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>2023.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>37.26</td>\n",
       "      <td>71.29</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>2019.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>449.0</td>\n",
       "      <td>37.15</td>\n",
       "      <td>71.00</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>2014.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>294.0</td>\n",
       "      <td>41.03</td>\n",
       "      <td>78.39</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows Ã— 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       year  month   day  hour   min    sec    lat    lon  depth  class  \\\n",
       "0    2018.0    2.0  14.0  23.0  21.0  505.0  38.46  73.45   60.0   10.7   \n",
       "1    2020.0   10.0   2.0   7.0  16.0  418.0  37.22  71.06   20.0   10.2   \n",
       "2    2016.0    4.0  15.0  15.0  21.0  269.0  51.05  89.48   10.0   10.9   \n",
       "3    2016.0    1.0  26.0  23.0  19.0  156.0  37.18  70.45    0.0   11.5   \n",
       "4    2021.0   10.0  26.0  17.0  47.0   43.0  42.27  83.46   10.0   11.0   \n",
       "..      ...    ...   ...   ...   ...    ...    ...    ...    ...    ...   \n",
       "295  2021.0    7.0  10.0   2.0  14.0  421.0  38.44  70.27   10.0   13.4   \n",
       "296  2016.0    4.0  27.0  10.0  54.0    2.0  37.53  71.42   25.0   10.2   \n",
       "297  2023.0    8.0  21.0   4.0  40.0  104.0  37.26  71.29    5.0   10.7   \n",
       "298  2019.0    9.0  29.0  22.0  47.0  449.0  37.15  71.00   10.0   10.3   \n",
       "299  2014.0    8.0  13.0   8.0  17.0  294.0  41.03  78.39    0.0   10.7   \n",
       "\n",
       "     year_as  month_as  day_as  hour_as  min_as  sec_as  lat_as  lon_as  \\\n",
       "0        NaN       NaN     NaN      NaN     NaN     NaN     NaN     NaN   \n",
       "1        NaN       NaN     NaN      NaN     NaN     NaN     NaN     NaN   \n",
       "2        NaN       NaN     NaN      NaN     NaN     NaN     NaN     NaN   \n",
       "3        NaN       NaN     NaN      NaN     NaN     NaN     NaN     NaN   \n",
       "4        NaN       NaN     NaN      NaN     NaN     NaN     NaN     NaN   \n",
       "..       ...       ...     ...      ...     ...     ...     ...     ...   \n",
       "295      NaN       NaN     NaN      NaN     NaN     NaN     NaN     NaN   \n",
       "296      NaN       NaN     NaN      NaN     NaN     NaN     NaN     NaN   \n",
       "297      NaN       NaN     NaN      NaN     NaN     NaN     NaN     NaN   \n",
       "298      NaN       NaN     NaN      NaN     NaN     NaN     NaN     NaN   \n",
       "299      NaN       NaN     NaN      NaN     NaN     NaN     NaN     NaN   \n",
       "\n",
       "     depth_as  class_as  \n",
       "0         NaN       NaN  \n",
       "1         NaN       NaN  \n",
       "2         NaN       NaN  \n",
       "3         NaN       NaN  \n",
       "4         NaN       NaN  \n",
       "..        ...       ...  \n",
       "295       NaN       NaN  \n",
       "296       NaN       NaN  \n",
       "297       NaN       NaN  \n",
       "298       NaN       NaN  \n",
       "299       NaN       NaN  \n",
       "\n",
       "[300 rows x 20 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.DataFrame()\n",
    "test_df[['year', 'month', 'day', 'hour', 'min', 'sec', 'lat', 'lon', 'depth', 'class']] = X\n",
    "test_df[['year_as', 'month_as', 'day_as', 'hour_as', 'min_as', 'sec_as', 'lat_as', 'lon_as', 'depth_as', 'class_as']] = np.nan\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e525656c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting with TabularPredictor for label: year_as ...\n",
      "Predicting with TabularPredictor for label: month_as ...\n",
      "Predicting with TabularPredictor for label: day_as ...\n",
      "Predicting with TabularPredictor for label: hour_as ...\n",
      "Predicting with TabularPredictor for label: min_as ...\n",
      "Predicting with TabularPredictor for label: sec_as ...\n",
      "Predicting with TabularPredictor for label: lat_as ...\n",
      "Predicting with TabularPredictor for label: lon_as ...\n",
      "Predicting with TabularPredictor for label: depth_as ...\n",
      "Predicting with TabularPredictor for label: class_as ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "year_as",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "month_as",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "day_as",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "hour_as",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "min_as",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "sec_as",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "lat_as",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "lon_as",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "depth_as",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "class_as",
         "rawType": "float32",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "d59bb457-1d45-423b-b35b-e6c879e3bd97",
       "rows": [
        [
         "0",
         "2013.0",
         "2.0",
         "18.0",
         "23.0",
         "22.0",
         "292.36978",
         "38.28728",
         "73.3071",
         "0.0",
         "8.063375"
        ],
        [
         "1",
         "2013.0",
         "10.0",
         "2.0",
         "8.0",
         "15.0",
         "291.2238",
         "37.204887",
         "71.11327",
         "0.0",
         "8.4061"
        ],
        [
         "2",
         "2013.0",
         "4.0",
         "15.0",
         "6.0",
         "51.0",
         "290.49127",
         "47.257507",
         "84.85193",
         "15.0",
         "7.898135"
        ],
        [
         "3",
         "2013.0",
         "1.0",
         "26.0",
         "23.0",
         "58.0",
         "288.8438",
         "37.184788",
         "70.46036",
         "5.0",
         "8.627711"
        ],
        [
         "4",
         "2013.0",
         "10.0",
         "27.0",
         "17.0",
         "45.0",
         "291.0264",
         "42.273518",
         "83.51734",
         "0.0",
         "8.079442"
        ],
        [
         "5",
         "2013.0",
         "2.0",
         "10.0",
         "20.0",
         "13.0",
         "292.36978",
         "37.190517",
         "71.1615",
         "0.0",
         "8.09674"
        ],
        [
         "6",
         "2013.0",
         "4.0",
         "10.0",
         "23.0",
         "5.0",
         "288.8438",
         "37.37255",
         "70.52506",
         "0.0",
         "8.552237"
        ],
        [
         "7",
         "2013.0",
         "1.0",
         "20.0",
         "6.0",
         "40.0",
         "290.49127",
         "44.44696",
         "78.40624",
         "10.0",
         "6.9378834"
        ],
        [
         "8",
         "2013.0",
         "5.0",
         "12.0",
         "18.0",
         "35.0",
         "291.2238",
         "37.302162",
         "71.35176",
         "0.0",
         "8.280434"
        ],
        [
         "9",
         "2013.0",
         "9.0",
         "1.0",
         "6.0",
         "27.0",
         "290.1612",
         "37.210857",
         "71.097885",
         "0.0",
         "8.411523"
        ],
        [
         "10",
         "2013.0",
         "4.0",
         "24.0",
         "15.0",
         "12.0",
         "292.87778",
         "37.072548",
         "70.49558",
         "0.0",
         "8.703345"
        ],
        [
         "11",
         "2013.0",
         "9.0",
         "29.0",
         "6.0",
         "39.0",
         "291.0264",
         "43.356853",
         "84.17685",
         "5.0",
         "7.7495933"
        ],
        [
         "12",
         "2013.0",
         "1.0",
         "12.0",
         "13.0",
         "25.0",
         "292.32944",
         "44.236763",
         "80.20966",
         "10.0",
         "7.319092"
        ],
        [
         "13",
         "2013.0",
         "1.0",
         "24.0",
         "20.0",
         "37.0",
         "288.8438",
         "36.397015",
         "71.261505",
         "5.0",
         "8.619266"
        ],
        [
         "14",
         "2013.0",
         "9.0",
         "18.0",
         "23.0",
         "30.0",
         "287.03247",
         "41.505833",
         "77.221306",
         "10.0",
         "7.2178607"
        ],
        [
         "15",
         "2013.0",
         "2.0",
         "22.0",
         "2.0",
         "45.0",
         "290.49127",
         "40.2047",
         "77.446526",
         "10.0",
         "7.8501387"
        ],
        [
         "16",
         "2013.0",
         "6.0",
         "26.0",
         "20.0",
         "20.0",
         "288.3012",
         "39.300766",
         "71.31835",
         "5.0",
         "8.361904"
        ],
        [
         "17",
         "2013.0",
         "4.0",
         "29.0",
         "0.0",
         "19.0",
         "292.87778",
         "37.35129",
         "73.164955",
         "0.0",
         "8.847711"
        ],
        [
         "18",
         "2013.0",
         "8.0",
         "6.0",
         "15.0",
         "9.0",
         "291.2238",
         "37.239365",
         "70.49484",
         "0.0",
         "8.36326"
        ],
        [
         "19",
         "2013.0",
         "10.0",
         "27.0",
         "10.0",
         "12.0",
         "291.0264",
         "41.165215",
         "78.424225",
         "10.0",
         "7.666912"
        ],
        [
         "20",
         "2013.0",
         "6.0",
         "27.0",
         "21.0",
         "41.0",
         "297.0978",
         "37.166912",
         "71.28502",
         "0.0",
         "8.162658"
        ],
        [
         "21",
         "2013.0",
         "4.0",
         "13.0",
         "9.0",
         "45.0",
         "291.1758",
         "38.422092",
         "70.51533",
         "0.0",
         "8.379787"
        ],
        [
         "22",
         "2013.0",
         "7.0",
         "23.0",
         "23.0",
         "18.0",
         "288.3012",
         "37.258114",
         "71.17653",
         "5.0",
         "8.604929"
        ],
        [
         "23",
         "2013.0",
         "1.0",
         "11.0",
         "4.0",
         "15.0",
         "291.1758",
         "37.2549",
         "71.117615",
         "0.0",
         "8.018545"
        ],
        [
         "24",
         "2013.0",
         "5.0",
         "5.0",
         "23.0",
         "9.0",
         "288.3012",
         "41.14981",
         "75.45056",
         "10.0",
         "7.409989"
        ],
        [
         "25",
         "2013.0",
         "4.0",
         "24.0",
         "20.0",
         "21.0",
         "287.17584",
         "42.515636",
         "77.396126",
         "10.0",
         "6.9040937"
        ],
        [
         "26",
         "2013.0",
         "12.0",
         "1.0",
         "23.0",
         "45.0",
         "288.3012",
         "37.169994",
         "71.23457",
         "0.0",
         "8.451957"
        ],
        [
         "27",
         "2013.0",
         "9.0",
         "17.0",
         "8.0",
         "15.0",
         "291.2238",
         "37.19492",
         "71.27181",
         "0.0",
         "8.564082"
        ],
        [
         "28",
         "2013.0",
         "5.0",
         "24.0",
         "8.0",
         "5.0",
         "291.2238",
         "37.069107",
         "70.297195",
         "0.0",
         "8.477039"
        ],
        [
         "29",
         "2013.0",
         "7.0",
         "19.0",
         "8.0",
         "19.0",
         "293.22025",
         "37.090645",
         "70.29248",
         "0.0",
         "8.889434"
        ],
        [
         "30",
         "2013.0",
         "4.0",
         "29.0",
         "14.0",
         "44.0",
         "288.58624",
         "40.255226",
         "74.43918",
         "5.0",
         "7.6146317"
        ],
        [
         "31",
         "2013.0",
         "7.0",
         "3.0",
         "20.0",
         "27.0",
         "288.3012",
         "36.431065",
         "71.06627",
         "0.0",
         "9.115177"
        ],
        [
         "32",
         "2013.0",
         "7.0",
         "30.0",
         "12.0",
         "32.0",
         "291.2238",
         "38.33053",
         "73.00538",
         "0.0",
         "8.477852"
        ],
        [
         "33",
         "2013.0",
         "3.0",
         "11.0",
         "11.0",
         "25.0",
         "292.32944",
         "43.084618",
         "80.04364",
         "10.0",
         "7.0950346"
        ],
        [
         "34",
         "2013.0",
         "12.0",
         "30.0",
         "23.0",
         "12.0",
         "297.0978",
         "38.30908",
         "72.24342",
         "0.0",
         "8.587519"
        ],
        [
         "35",
         "2013.0",
         "3.0",
         "30.0",
         "4.0",
         "32.0",
         "291.1758",
         "37.126293",
         "70.437836",
         "0.0",
         "8.636718"
        ],
        [
         "36",
         "2013.0",
         "12.0",
         "28.0",
         "1.0",
         "24.0",
         "293.22025",
         "37.286694",
         "70.45243",
         "0.0",
         "8.870788"
        ],
        [
         "37",
         "2013.0",
         "6.0",
         "6.0",
         "1.0",
         "25.0",
         "287.63507",
         "44.43835",
         "78.384995",
         "10.0",
         "6.93266"
        ],
        [
         "38",
         "2013.0",
         "3.0",
         "13.0",
         "16.0",
         "9.0",
         "291.1758",
         "37.379143",
         "72.147354",
         "0.0",
         "8.324266"
        ],
        [
         "39",
         "2013.0",
         "10.0",
         "27.0",
         "6.0",
         "52.0",
         "290.2204",
         "41.083405",
         "78.34575",
         "10.0",
         "7.930694"
        ],
        [
         "40",
         "2013.0",
         "2.0",
         "28.0",
         "4.0",
         "37.0",
         "291.1758",
         "38.178856",
         "73.13283",
         "5.0",
         "8.320327"
        ],
        [
         "41",
         "2013.0",
         "4.0",
         "4.0",
         "22.0",
         "13.0",
         "288.07004",
         "41.36296",
         "81.094894",
         "10.0",
         "7.561412"
        ],
        [
         "42",
         "2013.0",
         "11.0",
         "5.0",
         "6.0",
         "27.0",
         "291.2238",
         "37.314884",
         "71.09193",
         "0.0",
         "8.366894"
        ],
        [
         "43",
         "2013.0",
         "9.0",
         "4.0",
         "6.0",
         "27.0",
         "291.0264",
         "37.366886",
         "77.18747",
         "0.0",
         "8.4946785"
        ],
        [
         "44",
         "2013.0",
         "12.0",
         "27.0",
         "13.0",
         "57.0",
         "291.0264",
         "42.167534",
         "83.49186",
         "0.0",
         "8.156965"
        ],
        [
         "45",
         "2013.0",
         "1.0",
         "29.0",
         "20.0",
         "15.0",
         "288.8438",
         "37.42147",
         "71.17332",
         "0.0",
         "8.075523"
        ],
        [
         "46",
         "2013.0",
         "8.0",
         "4.0",
         "20.0",
         "55.0",
         "288.3012",
         "37.185112",
         "71.28209",
         "0.0",
         "8.4666195"
        ],
        [
         "47",
         "2013.0",
         "3.0",
         "20.0",
         "0.0",
         "32.0",
         "291.1758",
         "37.168415",
         "71.24707",
         "0.0",
         "8.568685"
        ],
        [
         "48",
         "2013.0",
         "4.0",
         "8.0",
         "21.0",
         "25.0",
         "288.07004",
         "42.528145",
         "78.214714",
         "10.0",
         "6.835494"
        ],
        [
         "49",
         "2013.0",
         "11.0",
         "29.0",
         "21.0",
         "3.0",
         "287.03247",
         "39.401344",
         "74.34818",
         "0.0",
         "7.926115"
        ]
       ],
       "shape": {
        "columns": 10,
        "rows": 300
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year_as</th>\n",
       "      <th>month_as</th>\n",
       "      <th>day_as</th>\n",
       "      <th>hour_as</th>\n",
       "      <th>min_as</th>\n",
       "      <th>sec_as</th>\n",
       "      <th>lat_as</th>\n",
       "      <th>lon_as</th>\n",
       "      <th>depth_as</th>\n",
       "      <th>class_as</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>292.369781</td>\n",
       "      <td>38.287281</td>\n",
       "      <td>73.307098</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.063375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>291.223785</td>\n",
       "      <td>37.204887</td>\n",
       "      <td>71.113274</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.406100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>290.491272</td>\n",
       "      <td>47.257507</td>\n",
       "      <td>84.851929</td>\n",
       "      <td>15.0</td>\n",
       "      <td>7.898135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>288.843811</td>\n",
       "      <td>37.184788</td>\n",
       "      <td>70.460358</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.627711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>291.026398</td>\n",
       "      <td>42.273518</td>\n",
       "      <td>83.517342</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.079442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>2013.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>292.567871</td>\n",
       "      <td>38.373669</td>\n",
       "      <td>70.311264</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.432604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>2013.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>291.175812</td>\n",
       "      <td>37.431652</td>\n",
       "      <td>71.336945</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.143601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>2013.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>291.223785</td>\n",
       "      <td>37.232819</td>\n",
       "      <td>71.235374</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.639359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>2013.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>288.301208</td>\n",
       "      <td>37.094131</td>\n",
       "      <td>70.975525</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.404770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>2013.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>291.026398</td>\n",
       "      <td>41.090729</td>\n",
       "      <td>78.299706</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.687637</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     year_as  month_as  day_as  hour_as  min_as      sec_as     lat_as  \\\n",
       "0     2013.0       2.0    18.0     23.0    22.0  292.369781  38.287281   \n",
       "1     2013.0      10.0     2.0      8.0    15.0  291.223785  37.204887   \n",
       "2     2013.0       4.0    15.0      6.0    51.0  290.491272  47.257507   \n",
       "3     2013.0       1.0    26.0     23.0    58.0  288.843811  37.184788   \n",
       "4     2013.0      10.0    27.0     17.0    45.0  291.026398  42.273518   \n",
       "..       ...       ...     ...      ...     ...         ...        ...   \n",
       "295   2013.0       7.0    10.0      2.0    44.0  292.567871  38.373669   \n",
       "296   2013.0       4.0    27.0     10.0     3.0  291.175812  37.431652   \n",
       "297   2013.0       8.0    21.0      6.0    15.0  291.223785  37.232819   \n",
       "298   2013.0      10.0    29.0     23.0    55.0  288.301208  37.094131   \n",
       "299   2013.0       8.0    13.0      9.0    48.0  291.026398  41.090729   \n",
       "\n",
       "        lon_as  depth_as  class_as  \n",
       "0    73.307098       0.0  8.063375  \n",
       "1    71.113274       0.0  8.406100  \n",
       "2    84.851929      15.0  7.898135  \n",
       "3    70.460358       5.0  8.627711  \n",
       "4    83.517342       0.0  8.079442  \n",
       "..         ...       ...       ...  \n",
       "295  70.311264       0.0  9.432604  \n",
       "296  71.336945       0.0  8.143601  \n",
       "297  71.235374       5.0  8.639359  \n",
       "298  70.975525       0.0  8.404770  \n",
       "299  78.299706      10.0  7.687637  \n",
       "\n",
       "[300 rows x 10 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = TabularDataset(test_df)\n",
    "\n",
    "predictions = multi_predictor.predict(test_data)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "02c3574c",
   "metadata": {},
   "outputs": [],
   "source": [
    "idq = pd.DataFrame()\n",
    "idq['id_eq'] = data_t['id_eq']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f303532d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "id_eq",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "year_as",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "month_as",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "day_as",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "hour_as",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "min_as",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "sec_as",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "lat_as",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "lon_as",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "depth_as",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "class_as",
         "rawType": "float32",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "3634d002-545c-48a0-ad78-5c009aeb27cf",
       "rows": [
        [
         "0",
         "996",
         "2013.0",
         "2.0",
         "18.0",
         "23.0",
         "22.0",
         "292.36978",
         "38.28728",
         "73.3071",
         "0.0",
         "8.063375"
        ],
        [
         "1",
         "1336",
         "2013.0",
         "10.0",
         "2.0",
         "8.0",
         "15.0",
         "291.2238",
         "37.204887",
         "71.11327",
         "0.0",
         "8.4061"
        ],
        [
         "2",
         "730",
         "2013.0",
         "4.0",
         "15.0",
         "6.0",
         "51.0",
         "290.49127",
         "47.257507",
         "84.85193",
         "15.0",
         "7.898135"
        ],
        [
         "3",
         "696",
         "2013.0",
         "1.0",
         "26.0",
         "23.0",
         "58.0",
         "288.8438",
         "37.184788",
         "70.46036",
         "5.0",
         "8.627711"
        ],
        [
         "4",
         "1460",
         "2013.0",
         "10.0",
         "27.0",
         "17.0",
         "45.0",
         "291.0264",
         "42.273518",
         "83.51734",
         "0.0",
         "8.079442"
        ],
        [
         "5",
         "1636",
         "2013.0",
         "2.0",
         "10.0",
         "20.0",
         "13.0",
         "292.36978",
         "37.190517",
         "71.1615",
         "0.0",
         "8.09674"
        ],
        [
         "6",
         "728",
         "2013.0",
         "4.0",
         "10.0",
         "23.0",
         "5.0",
         "288.8438",
         "37.37255",
         "70.52506",
         "0.0",
         "8.552237"
        ],
        [
         "7",
         "1233",
         "2013.0",
         "1.0",
         "20.0",
         "6.0",
         "40.0",
         "290.49127",
         "44.44696",
         "78.40624",
         "10.0",
         "6.9378834"
        ],
        [
         "8",
         "914",
         "2013.0",
         "5.0",
         "12.0",
         "18.0",
         "35.0",
         "291.2238",
         "37.302162",
         "71.35176",
         "0.0",
         "8.280434"
        ],
        [
         "9",
         "1324",
         "2013.0",
         "9.0",
         "1.0",
         "6.0",
         "27.0",
         "290.1612",
         "37.210857",
         "71.097885",
         "0.0",
         "8.411523"
        ],
        [
         "10",
         "1020",
         "2013.0",
         "4.0",
         "24.0",
         "15.0",
         "12.0",
         "292.87778",
         "37.072548",
         "70.49558",
         "0.0",
         "8.703345"
        ],
        [
         "11",
         "1436",
         "2013.0",
         "9.0",
         "29.0",
         "6.0",
         "39.0",
         "291.0264",
         "43.356853",
         "84.17685",
         "5.0",
         "7.7495933"
        ],
        [
         "12",
         "1377",
         "2013.0",
         "1.0",
         "12.0",
         "13.0",
         "25.0",
         "292.32944",
         "44.236763",
         "80.20966",
         "10.0",
         "7.319092"
        ],
        [
         "13",
         "446",
         "2013.0",
         "1.0",
         "24.0",
         "20.0",
         "37.0",
         "288.8438",
         "36.397015",
         "71.261505",
         "5.0",
         "8.619266"
        ],
        [
         "14",
         "1067",
         "2013.0",
         "9.0",
         "18.0",
         "23.0",
         "30.0",
         "287.03247",
         "41.505833",
         "77.221306",
         "10.0",
         "7.2178607"
        ],
        [
         "15",
         "876",
         "2013.0",
         "2.0",
         "22.0",
         "2.0",
         "45.0",
         "290.49127",
         "40.2047",
         "77.446526",
         "10.0",
         "7.8501387"
        ],
        [
         "16",
         "920",
         "2013.0",
         "6.0",
         "26.0",
         "20.0",
         "20.0",
         "288.3012",
         "39.300766",
         "71.31835",
         "5.0",
         "8.361904"
        ],
        [
         "17",
         "1136",
         "2013.0",
         "4.0",
         "29.0",
         "0.0",
         "19.0",
         "292.87778",
         "37.35129",
         "73.164955",
         "0.0",
         "8.847711"
        ],
        [
         "18",
         "1731",
         "2013.0",
         "8.0",
         "6.0",
         "15.0",
         "9.0",
         "291.2238",
         "37.239365",
         "70.49484",
         "0.0",
         "8.36326"
        ],
        [
         "19",
         "1197",
         "2013.0",
         "10.0",
         "27.0",
         "10.0",
         "12.0",
         "291.0264",
         "41.165215",
         "78.424225",
         "10.0",
         "7.666912"
        ],
        [
         "20",
         "1699",
         "2013.0",
         "6.0",
         "27.0",
         "21.0",
         "41.0",
         "297.0978",
         "37.166912",
         "71.28502",
         "0.0",
         "8.162658"
        ],
        [
         "21",
         "573",
         "2013.0",
         "4.0",
         "13.0",
         "9.0",
         "45.0",
         "291.1758",
         "38.422092",
         "70.51533",
         "0.0",
         "8.379787"
        ],
        [
         "22",
         "1429",
         "2013.0",
         "7.0",
         "23.0",
         "23.0",
         "18.0",
         "288.3012",
         "37.258114",
         "71.17653",
         "5.0",
         "8.604929"
        ],
        [
         "23",
         "1620",
         "2013.0",
         "1.0",
         "11.0",
         "4.0",
         "15.0",
         "291.1758",
         "37.2549",
         "71.117615",
         "0.0",
         "8.018545"
        ],
        [
         "24",
         "743",
         "2013.0",
         "5.0",
         "5.0",
         "23.0",
         "9.0",
         "288.3012",
         "41.14981",
         "75.45056",
         "10.0",
         "7.409989"
        ],
        [
         "25",
         "474",
         "2013.0",
         "4.0",
         "24.0",
         "20.0",
         "21.0",
         "287.17584",
         "42.515636",
         "77.396126",
         "10.0",
         "6.9040937"
        ],
        [
         "26",
         "1476",
         "2013.0",
         "12.0",
         "1.0",
         "23.0",
         "45.0",
         "288.3012",
         "37.169994",
         "71.23457",
         "0.0",
         "8.451957"
        ],
        [
         "27",
         "523",
         "2013.0",
         "9.0",
         "17.0",
         "8.0",
         "15.0",
         "291.2238",
         "37.19492",
         "71.27181",
         "0.0",
         "8.564082"
        ],
        [
         "28",
         "1529",
         "2013.0",
         "5.0",
         "24.0",
         "8.0",
         "5.0",
         "291.2238",
         "37.069107",
         "70.297195",
         "0.0",
         "8.477039"
        ],
        [
         "29",
         "1724",
         "2013.0",
         "7.0",
         "19.0",
         "8.0",
         "19.0",
         "293.22025",
         "37.090645",
         "70.29248",
         "0.0",
         "8.889434"
        ],
        [
         "30",
         "902",
         "2013.0",
         "4.0",
         "29.0",
         "14.0",
         "44.0",
         "288.58624",
         "40.255226",
         "74.43918",
         "5.0",
         "7.6146317"
        ],
        [
         "31",
         "1719",
         "2013.0",
         "7.0",
         "3.0",
         "20.0",
         "27.0",
         "288.3012",
         "36.431065",
         "71.06627",
         "0.0",
         "9.115177"
        ],
        [
         "32",
         "776",
         "2013.0",
         "7.0",
         "30.0",
         "12.0",
         "32.0",
         "291.2238",
         "38.33053",
         "73.00538",
         "0.0",
         "8.477852"
        ],
        [
         "33",
         "1253",
         "2013.0",
         "3.0",
         "11.0",
         "11.0",
         "25.0",
         "292.32944",
         "43.084618",
         "80.04364",
         "10.0",
         "7.0950346"
        ],
        [
         "34",
         "552",
         "2013.0",
         "12.0",
         "30.0",
         "23.0",
         "12.0",
         "297.0978",
         "38.30908",
         "72.24342",
         "0.0",
         "8.587519"
        ],
        [
         "35",
         "571",
         "2013.0",
         "3.0",
         "30.0",
         "4.0",
         "32.0",
         "291.1758",
         "37.126293",
         "70.437836",
         "0.0",
         "8.636718"
        ],
        [
         "36",
         "857",
         "2013.0",
         "12.0",
         "28.0",
         "1.0",
         "24.0",
         "293.22025",
         "37.286694",
         "70.45243",
         "0.0",
         "8.870788"
        ],
        [
         "37",
         "1293",
         "2013.0",
         "6.0",
         "6.0",
         "1.0",
         "25.0",
         "287.63507",
         "44.43835",
         "78.384995",
         "10.0",
         "6.93266"
        ],
        [
         "38",
         "884",
         "2013.0",
         "3.0",
         "13.0",
         "16.0",
         "9.0",
         "291.1758",
         "37.379143",
         "72.147354",
         "0.0",
         "8.324266"
        ],
        [
         "39",
         "1196",
         "2013.0",
         "10.0",
         "27.0",
         "6.0",
         "52.0",
         "290.2204",
         "41.083405",
         "78.34575",
         "10.0",
         "7.930694"
        ],
        [
         "40",
         "1651",
         "2013.0",
         "2.0",
         "28.0",
         "4.0",
         "37.0",
         "291.1758",
         "38.178856",
         "73.13283",
         "5.0",
         "8.320327"
        ],
        [
         "41",
         "1671",
         "2013.0",
         "4.0",
         "4.0",
         "22.0",
         "13.0",
         "288.07004",
         "41.36296",
         "81.094894",
         "10.0",
         "7.561412"
        ],
        [
         "42",
         "973",
         "2013.0",
         "11.0",
         "5.0",
         "6.0",
         "27.0",
         "291.2238",
         "37.314884",
         "71.09193",
         "0.0",
         "8.366894"
        ],
        [
         "43",
         "1441",
         "2013.0",
         "9.0",
         "4.0",
         "6.0",
         "27.0",
         "291.0264",
         "37.366886",
         "77.18747",
         "0.0",
         "8.4946785"
        ],
        [
         "44",
         "676",
         "2013.0",
         "12.0",
         "27.0",
         "13.0",
         "57.0",
         "291.0264",
         "42.167534",
         "83.49186",
         "0.0",
         "8.156965"
        ],
        [
         "45",
         "1118",
         "2013.0",
         "1.0",
         "29.0",
         "20.0",
         "15.0",
         "288.8438",
         "37.42147",
         "71.17332",
         "0.0",
         "8.075523"
        ],
        [
         "46",
         "1562",
         "2013.0",
         "8.0",
         "4.0",
         "20.0",
         "55.0",
         "288.3012",
         "37.185112",
         "71.28209",
         "0.0",
         "8.4666195"
        ],
        [
         "47",
         "716",
         "2013.0",
         "3.0",
         "20.0",
         "0.0",
         "32.0",
         "291.1758",
         "37.168415",
         "71.24707",
         "0.0",
         "8.568685"
        ],
        [
         "48",
         "1014",
         "2013.0",
         "4.0",
         "8.0",
         "21.0",
         "25.0",
         "288.07004",
         "42.528145",
         "78.214714",
         "10.0",
         "6.835494"
        ],
        [
         "49",
         "1599",
         "2013.0",
         "11.0",
         "29.0",
         "21.0",
         "3.0",
         "287.03247",
         "39.401344",
         "74.34818",
         "0.0",
         "7.926115"
        ]
       ],
       "shape": {
        "columns": 11,
        "rows": 300
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_eq</th>\n",
       "      <th>year_as</th>\n",
       "      <th>month_as</th>\n",
       "      <th>day_as</th>\n",
       "      <th>hour_as</th>\n",
       "      <th>min_as</th>\n",
       "      <th>sec_as</th>\n",
       "      <th>lat_as</th>\n",
       "      <th>lon_as</th>\n",
       "      <th>depth_as</th>\n",
       "      <th>class_as</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>996</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>292.369781</td>\n",
       "      <td>38.287281</td>\n",
       "      <td>73.307098</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.063375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1336</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>291.223785</td>\n",
       "      <td>37.204887</td>\n",
       "      <td>71.113274</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.406100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>730</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>290.491272</td>\n",
       "      <td>47.257507</td>\n",
       "      <td>84.851929</td>\n",
       "      <td>15.0</td>\n",
       "      <td>7.898135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>696</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>288.843811</td>\n",
       "      <td>37.184788</td>\n",
       "      <td>70.460358</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.627711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1460</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>291.026398</td>\n",
       "      <td>42.273518</td>\n",
       "      <td>83.517342</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.079442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>1422</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>292.567871</td>\n",
       "      <td>38.373669</td>\n",
       "      <td>70.311264</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.432604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>737</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>291.175812</td>\n",
       "      <td>37.431652</td>\n",
       "      <td>71.336945</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.143601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>1737</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>291.223785</td>\n",
       "      <td>37.232819</td>\n",
       "      <td>71.235374</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.639359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>1184</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>288.301208</td>\n",
       "      <td>37.094131</td>\n",
       "      <td>70.975525</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.404770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>503</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>291.026398</td>\n",
       "      <td>41.090729</td>\n",
       "      <td>78.299706</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.687637</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     id_eq  year_as  month_as  day_as  hour_as  min_as      sec_as     lat_as  \\\n",
       "0      996   2013.0       2.0    18.0     23.0    22.0  292.369781  38.287281   \n",
       "1     1336   2013.0      10.0     2.0      8.0    15.0  291.223785  37.204887   \n",
       "2      730   2013.0       4.0    15.0      6.0    51.0  290.491272  47.257507   \n",
       "3      696   2013.0       1.0    26.0     23.0    58.0  288.843811  37.184788   \n",
       "4     1460   2013.0      10.0    27.0     17.0    45.0  291.026398  42.273518   \n",
       "..     ...      ...       ...     ...      ...     ...         ...        ...   \n",
       "295   1422   2013.0       7.0    10.0      2.0    44.0  292.567871  38.373669   \n",
       "296    737   2013.0       4.0    27.0     10.0     3.0  291.175812  37.431652   \n",
       "297   1737   2013.0       8.0    21.0      6.0    15.0  291.223785  37.232819   \n",
       "298   1184   2013.0      10.0    29.0     23.0    55.0  288.301208  37.094131   \n",
       "299    503   2013.0       8.0    13.0      9.0    48.0  291.026398  41.090729   \n",
       "\n",
       "        lon_as  depth_as  class_as  \n",
       "0    73.307098       0.0  8.063375  \n",
       "1    71.113274       0.0  8.406100  \n",
       "2    84.851929      15.0  7.898135  \n",
       "3    70.460358       5.0  8.627711  \n",
       "4    83.517342       0.0  8.079442  \n",
       "..         ...       ...       ...  \n",
       "295  70.311264       0.0  9.432604  \n",
       "296  71.336945       0.0  8.143601  \n",
       "297  71.235374       5.0  8.639359  \n",
       "298  70.975525       0.0  8.404770  \n",
       "299  78.299706      10.0  7.687637  \n",
       "\n",
       "[300 rows x 11 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idq[['year_as', 'month_as', 'day_as', 'hour_as', 'min_as', 'sec_as', 'lat_as', 'lon_as', 'depth_as', 'class_as']] = predictions[['year_as', 'month_as', 'day_as', 'hour_as', 'min_as', 'sec_as', 'lat_as', 'lon_as', 'depth_as', 'class_as']]\n",
    "\n",
    "idq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b9f29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "idq.to_csv(\"test.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
